{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e04ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 04:55:39.428382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:39.428403: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_docs as tfdocs\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a32bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random \n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750d8e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>melspectrogram_mean</th>\n",
       "      <th>melspectrogram_var</th>\n",
       "      <th>mfcc_mean</th>\n",
       "      <th>mfcc_var</th>\n",
       "      <th>mfcc_delta_mean</th>\n",
       "      <th>mfcc_delta_var</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_var</th>\n",
       "      <th>cent_mean</th>\n",
       "      <th>cent_var</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>spec_bw_var</th>\n",
       "      <th>contrast_mean</th>\n",
       "      <th>contrast_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_var</th>\n",
       "      <th>poly_mean</th>\n",
       "      <th>poly_var</th>\n",
       "      <th>tonnetz_mean</th>\n",
       "      <th>tonnetz_var</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_var</th>\n",
       "      <th>harm_mean</th>\n",
       "      <th>harm_var</th>\n",
       "      <th>perc_mean</th>\n",
       "      <th>perc_var</th>\n",
       "      <th>frame_mean</th>\n",
       "      <th>frame_var</th>\n",
       "      <th>mfcc0_mean</th>\n",
       "      <th>mfcc0_var</th>\n",
       "      <th>mfcc1_mean</th>\n",
       "      <th>mfcc1_var</th>\n",
       "      <th>mfcc2_mean</th>\n",
       "      <th>mfcc2_var</th>\n",
       "      <th>mfcc3_mean</th>\n",
       "      <th>mfcc3_var</th>\n",
       "      <th>mfcc4_mean</th>\n",
       "      <th>mfcc4_var</th>\n",
       "      <th>mfcc5_mean</th>\n",
       "      <th>mfcc5_var</th>\n",
       "      <th>mfcc6_mean</th>\n",
       "      <th>mfcc6_var</th>\n",
       "      <th>mfcc7_mean</th>\n",
       "      <th>mfcc7_var</th>\n",
       "      <th>mfcc8_mean</th>\n",
       "      <th>mfcc8_var</th>\n",
       "      <th>mfcc9_mean</th>\n",
       "      <th>mfcc9_var</th>\n",
       "      <th>mfcc10_mean</th>\n",
       "      <th>mfcc10_var</th>\n",
       "      <th>mfcc11_mean</th>\n",
       "      <th>mfcc11_var</th>\n",
       "      <th>mfcc12_mean</th>\n",
       "      <th>mfcc12_var</th>\n",
       "      <th>mfcc13_mean</th>\n",
       "      <th>mfcc13_var</th>\n",
       "      <th>mfcc14_mean</th>\n",
       "      <th>mfcc14_var</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>app_3001_4001_phnd_neg_0000.wav</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>623</td>\n",
       "      <td>69.222222</td>\n",
       "      <td>0.515281</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.087981</td>\n",
       "      <td>-16.290880</td>\n",
       "      <td>8822.263672</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>7.908705</td>\n",
       "      <td>0.043470</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>1833.579533</td>\n",
       "      <td>511344.031721</td>\n",
       "      <td>1746.559035</td>\n",
       "      <td>144881.971359</td>\n",
       "      <td>19.095815</td>\n",
       "      <td>319.628529</td>\n",
       "      <td>3827.147750</td>\n",
       "      <td>3827.147750</td>\n",
       "      <td>0.294635</td>\n",
       "      <td>0.294635</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>0.114622</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>2.852700e-06</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>7.470300e-06</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>1.729204</td>\n",
       "      <td>0.945134</td>\n",
       "      <td>-389.578400</td>\n",
       "      <td>1394.284424</td>\n",
       "      <td>134.581345</td>\n",
       "      <td>694.736450</td>\n",
       "      <td>-39.877445</td>\n",
       "      <td>331.621368</td>\n",
       "      <td>55.018433</td>\n",
       "      <td>417.293945</td>\n",
       "      <td>-36.944489</td>\n",
       "      <td>246.965225</td>\n",
       "      <td>18.573177</td>\n",
       "      <td>270.046539</td>\n",
       "      <td>-19.398455</td>\n",
       "      <td>136.647842</td>\n",
       "      <td>4.641793</td>\n",
       "      <td>166.485138</td>\n",
       "      <td>-5.455597</td>\n",
       "      <td>105.498589</td>\n",
       "      <td>-6.548687</td>\n",
       "      <td>143.077621</td>\n",
       "      <td>1.620288</td>\n",
       "      <td>80.328003</td>\n",
       "      <td>-14.974999</td>\n",
       "      <td>55.536694</td>\n",
       "      <td>1.443957</td>\n",
       "      <td>105.002190</td>\n",
       "      <td>-10.213489</td>\n",
       "      <td>52.869869</td>\n",
       "      <td>0.718760</td>\n",
       "      <td>75.744896</td>\n",
       "      <td>-10.669799</td>\n",
       "      <td>63.340282</td>\n",
       "      <td>1.811605</td>\n",
       "      <td>58.117188</td>\n",
       "      <td>-3.286546</td>\n",
       "      <td>54.268448</td>\n",
       "      <td>-2.719069</td>\n",
       "      <td>59.548176</td>\n",
       "      <td>-4.559987</td>\n",
       "      <td>70.774803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_3001_4001_phnd_neg_0001.wav</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.542182</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.274423</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.204988</td>\n",
       "      <td>5.152482</td>\n",
       "      <td>-16.183870</td>\n",
       "      <td>7335.709961</td>\n",
       "      <td>-0.025494</td>\n",
       "      <td>18.772476</td>\n",
       "      <td>0.090213</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>1927.253538</td>\n",
       "      <td>354369.575716</td>\n",
       "      <td>1627.620214</td>\n",
       "      <td>68783.641466</td>\n",
       "      <td>19.186873</td>\n",
       "      <td>305.084512</td>\n",
       "      <td>3762.586531</td>\n",
       "      <td>3762.586531</td>\n",
       "      <td>0.583882</td>\n",
       "      <td>0.583882</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.122172</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>-1.651200e-06</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>-2.788160e-05</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>1.793741</td>\n",
       "      <td>0.910349</td>\n",
       "      <td>-350.381317</td>\n",
       "      <td>5990.534668</td>\n",
       "      <td>112.355591</td>\n",
       "      <td>596.321411</td>\n",
       "      <td>-50.575706</td>\n",
       "      <td>1418.432983</td>\n",
       "      <td>39.114021</td>\n",
       "      <td>507.006927</td>\n",
       "      <td>-33.239597</td>\n",
       "      <td>416.781708</td>\n",
       "      <td>3.573578</td>\n",
       "      <td>236.576492</td>\n",
       "      <td>-11.785189</td>\n",
       "      <td>178.042618</td>\n",
       "      <td>-1.014654</td>\n",
       "      <td>178.834152</td>\n",
       "      <td>4.223846</td>\n",
       "      <td>226.874054</td>\n",
       "      <td>-8.432135</td>\n",
       "      <td>133.631943</td>\n",
       "      <td>-0.922831</td>\n",
       "      <td>75.745110</td>\n",
       "      <td>-14.040901</td>\n",
       "      <td>129.677872</td>\n",
       "      <td>-1.542051</td>\n",
       "      <td>89.679306</td>\n",
       "      <td>-2.871657</td>\n",
       "      <td>86.871460</td>\n",
       "      <td>-2.855503</td>\n",
       "      <td>106.239403</td>\n",
       "      <td>-5.666375</td>\n",
       "      <td>90.256195</td>\n",
       "      <td>1.573594</td>\n",
       "      <td>105.070496</td>\n",
       "      <td>-0.742024</td>\n",
       "      <td>82.417496</td>\n",
       "      <td>-1.961745</td>\n",
       "      <td>119.312355</td>\n",
       "      <td>1.513660</td>\n",
       "      <td>101.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_3001_4001_phnd_neg_0002.wav</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>1614</td>\n",
       "      <td>146.727273</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>3.372185</td>\n",
       "      <td>-15.555374</td>\n",
       "      <td>7140.790039</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>10.850190</td>\n",
       "      <td>0.099754</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>1558.350787</td>\n",
       "      <td>286662.686733</td>\n",
       "      <td>1480.320551</td>\n",
       "      <td>108552.760715</td>\n",
       "      <td>19.694916</td>\n",
       "      <td>271.168203</td>\n",
       "      <td>3027.938960</td>\n",
       "      <td>3027.938960</td>\n",
       "      <td>0.626042</td>\n",
       "      <td>0.626042</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.012586</td>\n",
       "      <td>0.094763</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>-2.344000e-07</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>1.925600e-06</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>2.204735</td>\n",
       "      <td>1.657315</td>\n",
       "      <td>-340.841705</td>\n",
       "      <td>2853.958740</td>\n",
       "      <td>139.396652</td>\n",
       "      <td>639.750854</td>\n",
       "      <td>-44.360332</td>\n",
       "      <td>786.586487</td>\n",
       "      <td>34.030853</td>\n",
       "      <td>405.441681</td>\n",
       "      <td>-37.146648</td>\n",
       "      <td>447.909576</td>\n",
       "      <td>1.166850</td>\n",
       "      <td>360.854797</td>\n",
       "      <td>-11.257973</td>\n",
       "      <td>170.027328</td>\n",
       "      <td>-3.371944</td>\n",
       "      <td>226.699600</td>\n",
       "      <td>1.764457</td>\n",
       "      <td>140.997101</td>\n",
       "      <td>-9.144030</td>\n",
       "      <td>123.745407</td>\n",
       "      <td>0.545947</td>\n",
       "      <td>68.511703</td>\n",
       "      <td>-12.346964</td>\n",
       "      <td>91.306229</td>\n",
       "      <td>-3.448010</td>\n",
       "      <td>96.648567</td>\n",
       "      <td>-4.782896</td>\n",
       "      <td>96.846092</td>\n",
       "      <td>-3.135671</td>\n",
       "      <td>85.535561</td>\n",
       "      <td>-5.502390</td>\n",
       "      <td>73.079750</td>\n",
       "      <td>0.202623</td>\n",
       "      <td>72.040550</td>\n",
       "      <td>-4.021009</td>\n",
       "      <td>73.844353</td>\n",
       "      <td>-5.916223</td>\n",
       "      <td>103.834824</td>\n",
       "      <td>-2.939086</td>\n",
       "      <td>113.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>app_3001_4001_phnd_neg_0003.wav</td>\n",
       "      <td>107.666016</td>\n",
       "      <td>2060</td>\n",
       "      <td>158.461538</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>0.214154</td>\n",
       "      <td>3.943239</td>\n",
       "      <td>-16.382410</td>\n",
       "      <td>7671.897461</td>\n",
       "      <td>-0.017487</td>\n",
       "      <td>10.714126</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>1501.958914</td>\n",
       "      <td>236170.752891</td>\n",
       "      <td>1468.111222</td>\n",
       "      <td>100434.245015</td>\n",
       "      <td>19.731574</td>\n",
       "      <td>280.614702</td>\n",
       "      <td>2981.342123</td>\n",
       "      <td>2981.342123</td>\n",
       "      <td>0.544611</td>\n",
       "      <td>0.544611</td>\n",
       "      <td>0.024137</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>-4.205000e-07</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>-2.248000e-07</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>1.789098</td>\n",
       "      <td>1.241672</td>\n",
       "      <td>-359.523376</td>\n",
       "      <td>3351.339844</td>\n",
       "      <td>135.395157</td>\n",
       "      <td>589.953613</td>\n",
       "      <td>-40.197311</td>\n",
       "      <td>840.564270</td>\n",
       "      <td>32.704830</td>\n",
       "      <td>312.519379</td>\n",
       "      <td>-28.228338</td>\n",
       "      <td>411.952454</td>\n",
       "      <td>0.862422</td>\n",
       "      <td>276.248840</td>\n",
       "      <td>-9.016964</td>\n",
       "      <td>178.003738</td>\n",
       "      <td>-6.123117</td>\n",
       "      <td>168.513107</td>\n",
       "      <td>1.593995</td>\n",
       "      <td>121.375755</td>\n",
       "      <td>-7.000763</td>\n",
       "      <td>103.869049</td>\n",
       "      <td>-3.331117</td>\n",
       "      <td>89.101837</td>\n",
       "      <td>-12.368806</td>\n",
       "      <td>100.109505</td>\n",
       "      <td>-4.700512</td>\n",
       "      <td>99.216591</td>\n",
       "      <td>-5.343085</td>\n",
       "      <td>74.244865</td>\n",
       "      <td>-3.944259</td>\n",
       "      <td>76.465134</td>\n",
       "      <td>-8.812989</td>\n",
       "      <td>93.791893</td>\n",
       "      <td>-0.429413</td>\n",
       "      <td>60.002579</td>\n",
       "      <td>-4.013513</td>\n",
       "      <td>82.544540</td>\n",
       "      <td>-5.858006</td>\n",
       "      <td>84.402092</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>90.126389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>app_3001_4001_phnd_neg_0004.wav</td>\n",
       "      <td>75.999540</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.089313</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.128487</td>\n",
       "      <td>0.792460</td>\n",
       "      <td>-17.224360</td>\n",
       "      <td>8488.603516</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>8.329871</td>\n",
       "      <td>0.079344</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>1395.230033</td>\n",
       "      <td>281802.432273</td>\n",
       "      <td>1441.533673</td>\n",
       "      <td>145394.091098</td>\n",
       "      <td>19.596951</td>\n",
       "      <td>282.358081</td>\n",
       "      <td>2799.582248</td>\n",
       "      <td>2799.582248</td>\n",
       "      <td>0.463039</td>\n",
       "      <td>0.463039</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-1.697100e-06</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-2.288400e-06</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>1.885705</td>\n",
       "      <td>1.133871</td>\n",
       "      <td>-377.545197</td>\n",
       "      <td>2084.742920</td>\n",
       "      <td>149.727615</td>\n",
       "      <td>806.048401</td>\n",
       "      <td>-39.882656</td>\n",
       "      <td>449.930267</td>\n",
       "      <td>41.879189</td>\n",
       "      <td>472.226166</td>\n",
       "      <td>-30.462873</td>\n",
       "      <td>235.521164</td>\n",
       "      <td>7.132905</td>\n",
       "      <td>275.070709</td>\n",
       "      <td>-14.036365</td>\n",
       "      <td>134.910324</td>\n",
       "      <td>-3.452546</td>\n",
       "      <td>128.165848</td>\n",
       "      <td>-8.529839</td>\n",
       "      <td>109.861977</td>\n",
       "      <td>-12.826930</td>\n",
       "      <td>100.156181</td>\n",
       "      <td>-2.546823</td>\n",
       "      <td>54.763493</td>\n",
       "      <td>-15.552882</td>\n",
       "      <td>68.453285</td>\n",
       "      <td>-1.928557</td>\n",
       "      <td>86.908035</td>\n",
       "      <td>-9.201928</td>\n",
       "      <td>76.018440</td>\n",
       "      <td>-3.700468</td>\n",
       "      <td>72.502159</td>\n",
       "      <td>-6.584204</td>\n",
       "      <td>64.973305</td>\n",
       "      <td>0.744403</td>\n",
       "      <td>68.908516</td>\n",
       "      <td>-6.354805</td>\n",
       "      <td>66.414391</td>\n",
       "      <td>-6.555534</td>\n",
       "      <td>47.852840</td>\n",
       "      <td>-4.809713</td>\n",
       "      <td>73.033966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename       tempo  total_beats  average_beats  \\\n",
       "0  app_3001_4001_phnd_neg_0000.wav  184.570312          623      69.222222   \n",
       "1  app_3001_4001_phnd_neg_0001.wav  151.999081          521      74.428571   \n",
       "2  app_3001_4001_phnd_neg_0002.wav  112.347147         1614     146.727273   \n",
       "3  app_3001_4001_phnd_neg_0003.wav  107.666016         2060     158.461538   \n",
       "4  app_3001_4001_phnd_neg_0004.wav   75.999540           66      33.000000   \n",
       "\n",
       "   chroma_stft_mean  chroma_stft_var  chroma_cq_mean  chroma_cq_var  \\\n",
       "0          0.515281         0.093347        0.443441       0.082742   \n",
       "1          0.487201         0.094461        0.542182       0.073359   \n",
       "2          0.444244         0.099268        0.442014       0.083224   \n",
       "3          0.454156         0.100834        0.424370       0.084435   \n",
       "4          0.478780         0.100000        0.414859       0.089313   \n",
       "\n",
       "   chroma_cens_mean  chroma_cens_var  melspectrogram_mean  melspectrogram_var  \\\n",
       "0          0.249143         0.021261             0.038422            0.087981   \n",
       "1          0.274423         0.008025             0.204988            5.152482   \n",
       "2          0.264430         0.013410             0.218063            3.372185   \n",
       "3          0.257672         0.016938             0.214154            3.943239   \n",
       "4          0.252143         0.019757             0.128487            0.792460   \n",
       "\n",
       "   mfcc_mean     mfcc_var  mfcc_delta_mean  mfcc_delta_var  rmse_mean  \\\n",
       "0 -16.290880  8822.263672         0.014360        7.908705   0.043470   \n",
       "1 -16.183870  7335.709961        -0.025494       18.772476   0.090213   \n",
       "2 -15.555374  7140.790039        -0.001268       10.850190   0.099754   \n",
       "3 -16.382410  7671.897461        -0.017487       10.714126   0.092214   \n",
       "4 -17.224360  8488.603516         0.012062        8.329871   0.079344   \n",
       "\n",
       "   rmse_var    cent_mean       cent_var  spec_bw_mean    spec_bw_var  \\\n",
       "0  0.000818  1833.579533  511344.031721   1746.559035  144881.971359   \n",
       "1  0.008415  1927.253538  354369.575716   1627.620214   68783.641466   \n",
       "2  0.005438  1558.350787  286662.686733   1480.320551  108552.760715   \n",
       "3  0.006496  1501.958914  236170.752891   1468.111222  100434.245015   \n",
       "4  0.002560  1395.230033  281802.432273   1441.533673  145394.091098   \n",
       "\n",
       "   contrast_mean  contrast_var  rolloff_mean  rolloff_var  poly_mean  \\\n",
       "0      19.095815    319.628529   3827.147750  3827.147750   0.294635   \n",
       "1      19.186873    305.084512   3762.586531  3762.586531   0.583882   \n",
       "2      19.694916    271.168203   3027.938960  3027.938960   0.626042   \n",
       "3      19.731574    280.614702   2981.342123  2981.342123   0.544611   \n",
       "4      19.596951    282.358081   2799.582248  2799.582248   0.463039   \n",
       "\n",
       "   poly_var  tonnetz_mean  tonnetz_var  zcr_mean   zcr_var     harm_mean  \\\n",
       "0  0.294635      0.015770     0.012313  0.114622  0.004777  2.852700e-06   \n",
       "1  0.583882      0.015399     0.006057  0.122172  0.003331 -1.651200e-06   \n",
       "2  0.626042      0.000772     0.012586  0.094763  0.002338 -2.344000e-07   \n",
       "3  0.544611      0.024137     0.015121  0.085925  0.001861 -4.205000e-07   \n",
       "4  0.463039      0.002951     0.011803  0.076100  0.001372 -1.697100e-06   \n",
       "\n",
       "   harm_var     perc_mean  perc_var  frame_mean  frame_var  mfcc0_mean  \\\n",
       "0  0.001529  7.470300e-06  0.000618    1.729204   0.945134 -389.578400   \n",
       "1  0.002638 -2.788160e-05  0.009359    1.793741   0.910349 -350.381317   \n",
       "2  0.005676  1.925600e-06  0.005432    2.204735   1.657315 -340.841705   \n",
       "3  0.006873 -2.248000e-07  0.004422    1.789098   1.241672 -359.523376   \n",
       "4  0.003972 -2.288400e-06  0.002766    1.885705   1.133871 -377.545197   \n",
       "\n",
       "     mfcc0_var  mfcc1_mean   mfcc1_var  mfcc2_mean    mfcc2_var  mfcc3_mean  \\\n",
       "0  1394.284424  134.581345  694.736450  -39.877445   331.621368   55.018433   \n",
       "1  5990.534668  112.355591  596.321411  -50.575706  1418.432983   39.114021   \n",
       "2  2853.958740  139.396652  639.750854  -44.360332   786.586487   34.030853   \n",
       "3  3351.339844  135.395157  589.953613  -40.197311   840.564270   32.704830   \n",
       "4  2084.742920  149.727615  806.048401  -39.882656   449.930267   41.879189   \n",
       "\n",
       "    mfcc3_var  mfcc4_mean   mfcc4_var  mfcc5_mean   mfcc5_var  mfcc6_mean  \\\n",
       "0  417.293945  -36.944489  246.965225   18.573177  270.046539  -19.398455   \n",
       "1  507.006927  -33.239597  416.781708    3.573578  236.576492  -11.785189   \n",
       "2  405.441681  -37.146648  447.909576    1.166850  360.854797  -11.257973   \n",
       "3  312.519379  -28.228338  411.952454    0.862422  276.248840   -9.016964   \n",
       "4  472.226166  -30.462873  235.521164    7.132905  275.070709  -14.036365   \n",
       "\n",
       "    mfcc6_var  mfcc7_mean   mfcc7_var  mfcc8_mean   mfcc8_var  mfcc9_mean  \\\n",
       "0  136.647842    4.641793  166.485138   -5.455597  105.498589   -6.548687   \n",
       "1  178.042618   -1.014654  178.834152    4.223846  226.874054   -8.432135   \n",
       "2  170.027328   -3.371944  226.699600    1.764457  140.997101   -9.144030   \n",
       "3  178.003738   -6.123117  168.513107    1.593995  121.375755   -7.000763   \n",
       "4  134.910324   -3.452546  128.165848   -8.529839  109.861977  -12.826930   \n",
       "\n",
       "    mfcc9_var  mfcc10_mean  mfcc10_var  mfcc11_mean  mfcc11_var  mfcc12_mean  \\\n",
       "0  143.077621     1.620288   80.328003   -14.974999   55.536694     1.443957   \n",
       "1  133.631943    -0.922831   75.745110   -14.040901  129.677872    -1.542051   \n",
       "2  123.745407     0.545947   68.511703   -12.346964   91.306229    -3.448010   \n",
       "3  103.869049    -3.331117   89.101837   -12.368806  100.109505    -4.700512   \n",
       "4  100.156181    -2.546823   54.763493   -15.552882   68.453285    -1.928557   \n",
       "\n",
       "   mfcc12_var  mfcc13_mean  mfcc13_var  mfcc14_mean  mfcc14_var  mfcc15_mean  \\\n",
       "0  105.002190   -10.213489   52.869869     0.718760   75.744896   -10.669799   \n",
       "1   89.679306    -2.871657   86.871460    -2.855503  106.239403    -5.666375   \n",
       "2   96.648567    -4.782896   96.846092    -3.135671   85.535561    -5.502390   \n",
       "3   99.216591    -5.343085   74.244865    -3.944259   76.465134    -8.812989   \n",
       "4   86.908035    -9.201928   76.018440    -3.700468   72.502159    -6.584204   \n",
       "\n",
       "   mfcc15_var  mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  \\\n",
       "0   63.340282     1.811605   58.117188    -3.286546   54.268448    -2.719069   \n",
       "1   90.256195     1.573594  105.070496    -0.742024   82.417496    -1.961745   \n",
       "2   73.079750     0.202623   72.040550    -4.021009   73.844353    -5.916223   \n",
       "3   93.791893    -0.429413   60.002579    -4.013513   82.544540    -5.858006   \n",
       "4   64.973305     0.744403   68.908516    -6.354805   66.414391    -6.555534   \n",
       "\n",
       "   mfcc18_var  mfcc19_mean  mfcc19_var  \n",
       "0   59.548176    -4.559987   70.774803  \n",
       "1  119.312355     1.513660  101.014572  \n",
       "2  103.834824    -2.939086  113.598824  \n",
       "3   84.402092     0.686969   90.126389  \n",
       "4   47.852840    -4.809713   73.033966  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/full.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccad72",
   "metadata": {},
   "source": [
    "## a) Plot the mean cross-validation accuracies on the final epoch for different numbers of hidden-layer neurons using a scatter plot. Limit the search space of the number of neurons to {64, 128, 256}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d92c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['filename'].str.split('_').str[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594ab746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    92826\n",
       "neg    89428\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8312f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ab8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "  return tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dffd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback to save the entire model\n",
    "def saveModelsCallback(path,monitor,mode,save_freq):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=path,\n",
    "        monitor = monitor,\n",
    "        verbose = 0,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = False,\n",
    "        mode = mode,\n",
    "        save_freq=save_freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc17702",
   "metadata": {},
   "outputs": [],
   "source": [
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.last_time=0\n",
    "        self.initial_time = time.time()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        self.last_time = time.time() - self.initial_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5a0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['label','filename']\n",
    "\n",
    "def split_dataset(df, columns_to_drop, test_size, random_state):\n",
    "  label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "  df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "  df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "\n",
    "  df_train2 = df_train.drop(columns_to_drop,axis=1)\n",
    "  y_train2 = df_train['label'].to_numpy()\n",
    "\n",
    "  df_test2 = df_test.drop(columns_to_drop,axis=1)\n",
    "  y_test2 = df_test['label'].to_numpy() \n",
    "\n",
    "  return df_train2, y_train2, df_test2, y_test2\n",
    "\n",
    "def preprocess_dataset(df_train, df_test):\n",
    "\n",
    "  standard_scaler = preprocessing.StandardScaler()\n",
    "  df_train_scaled = standard_scaler.fit_transform(df_train)\n",
    "\n",
    "  df_test_scaled = standard_scaler.transform(df_test)\n",
    "\n",
    "  return df_train_scaled, df_test_scaled\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=0) # positive labels being encoded as 1\n",
    "\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97d1b1",
   "metadata": {},
   "source": [
    "### Functions to build and compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61cd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "def build_model(input_shape, no_neurons_hidden,first_layer_units,dropout_prob):\n",
    "    model = Sequential([\n",
    "                InputLayer(input_shape),\n",
    "                Dense(first_layer_units,activation='relu'),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(no_neurons_hidden,activation='relu'),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(no_neurons_hidden,activation='relu'),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(2,activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def compile_and_train(model,no_epochs,lr,batch_size,x_train,y_train,x_test,y_test,model_path):\n",
    "    \n",
    "    model.compile(optimizer = Adam(learning_rate = lr), \n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=[\n",
    "                'accuracy',\n",
    "                'mean_squared_error'\n",
    "             ])\n",
    "            \n",
    "            # use an instance to persist the callback data\n",
    "    timecallbackinstance = timecallback()\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=no_epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        verbose=0,\n",
    "                        callbacks= [get_callbacks(),\n",
    "                                    timecallbackinstance,\n",
    "                                   saveModelsCallback(model_path,\n",
    "                                                       'val_loss',\n",
    "                                                       'min',\n",
    "                                                       'epoch')\n",
    "                                   ],\n",
    "                        use_multiprocessing=True,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    return history,timecallbackinstance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a396a",
   "metadata": {},
   "source": [
    "### function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8948d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train model\n",
    "no_folds = 5\n",
    "total_data = X_train_scaled.shape[0]\n",
    "no_epochs = 100\n",
    "lr = 0.001\n",
    "dropout_prob = 0.2\n",
    "no_neurons_hidden = 128\n",
    "hidden_units = [64, 128, 256]\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "def train_exp(X, Y):\n",
    "    \n",
    "    err = []\n",
    "    accuracy=[]\n",
    "    last_epoch_times =[]\n",
    "    histories = []\n",
    "    \n",
    "    \n",
    "    for hidden_unit in hidden_units:\n",
    "        histories_ =[]\n",
    "        accuracy_ =[]\n",
    "        err_ = []\n",
    "        last_epoch_times_ = []\n",
    "    \n",
    "        for fold in range(no_folds):\n",
    "            start, end = fold*(total_data//5), (fold+1)*(total_data//5)\n",
    "\n",
    "            x_test, y_test = X[start:end], Y[start:end]\n",
    "            x_train  = np.append(X[:start], X[end:], axis=0)\n",
    "            y_train = np.append(Y[:start], Y[end:], axis=0)\n",
    "\n",
    "            # specify dir to save weights of best epochs for each fold for each batch size\n",
    "            model_path = './data/models/PartA_Q3a/{}_units_{}_fold_/best_epoch_weights'.format(hidden_unit,fold+1)\n",
    "            \n",
    "            model = build_model((x_train.shape[1],),\n",
    "                                no_neurons_hidden,\n",
    "                                hidden_unit,\n",
    "                               dropout_prob)\n",
    "            history,timecallbackinstance = compile_and_train(model,\n",
    "                                        no_epochs,\n",
    "                                        lr,\n",
    "                                        batch_size,\n",
    "                                        x_train,\n",
    "                                        y_train,\n",
    "                                        x_test,\n",
    "                                        y_test,\n",
    "                                        model_path)\n",
    "            \n",
    "            err_.append(min(history.history['val_loss']))\n",
    "            accuracy_.append(history.history['val_accuracy'][-1])\n",
    "            last_epoch_times_.append(timecallbackinstance.last_time)\n",
    "            histories_.append(history)\n",
    "    \n",
    "        err.append(np.mean(err_))\n",
    "        accuracy.append(np.mean(accuracy_))\n",
    "        last_epoch_times.append(np.mean(last_epoch_times_))\n",
    "        histories.append(histories_)\n",
    "\n",
    "    return err,accuracy,last_epoch_times,histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6da3579",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 04:55:43.461587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-10 04:55:43.462081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.462191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.462292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.464911: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.465046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.465152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-10 04:55:43.465165: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-10 04:55:43.465518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68635, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68635 to 0.68353, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68353 to 0.68191, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68191 to 0.68107, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68107 to 0.67894, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67894 to 0.67738, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67738 to 0.67572, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67572 to 0.67474, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67474 to 0.67296, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67296 to 0.67134, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.67134 to 0.66931, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66931 to 0.66873, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.66873 to 0.66621, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.66621\n",
      "\n",
      "Epoch 15: val_loss improved from 0.66621 to 0.66270, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.66270 to 0.66225, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.66225 to 0.66027, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.66027\n",
      "\n",
      "Epoch 19: val_loss improved from 0.66027 to 0.65778, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.65778\n",
      "\n",
      "Epoch 21: val_loss improved from 0.65778 to 0.65742, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.65742 to 0.65438, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.65438\n",
      "\n",
      "Epoch 24: val_loss improved from 0.65438 to 0.65219, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.65219\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65219\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.65219\n",
      "\n",
      "Epoch 28: val_loss improved from 0.65219 to 0.65169, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.65169\n",
      "\n",
      "Epoch 30: val_loss improved from 0.65169 to 0.65025, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.65025 to 0.64889, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.64889 to 0.64772, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.64772 to 0.64619, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.64619\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.64619\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.64619\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.64619\n",
      "\n",
      "Epoch 38: val_loss improved from 0.64619 to 0.64353, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.64353 to 0.64321, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.64321 to 0.64314, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.64314\n",
      "\n",
      "Epoch 42: val_loss improved from 0.64314 to 0.64297, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.64297\n",
      "\n",
      "Epoch 44: val_loss improved from 0.64297 to 0.64235, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.64235 to 0.64100, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.64100\n",
      "\n",
      "Epoch 47: val_loss improved from 0.64100 to 0.64079, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.64079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49: val_loss improved from 0.64079 to 0.64041, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss improved from 0.64041 to 0.63877, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss improved from 0.63877 to 0.63848, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.63848\n",
      "\n",
      "Epoch 53: val_loss improved from 0.63848 to 0.63784, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.63784\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.63784\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.63784\n",
      "\n",
      "Epoch 57: val_loss improved from 0.63784 to 0.63528, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.63528\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.63528\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.63528\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.63528\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.63528\n",
      "\n",
      "Epoch 63: val_loss improved from 0.63528 to 0.63492, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.63492\n",
      "\n",
      "Epoch 65: val_loss improved from 0.63492 to 0.63366, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.63366\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.63366\n",
      "\n",
      "Epoch 68: val_loss improved from 0.63366 to 0.63363, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.63363\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.63363\n",
      "\n",
      "Epoch 71: val_loss improved from 0.63363 to 0.63230, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.63230\n",
      "\n",
      "Epoch 73: val_loss improved from 0.63230 to 0.63113, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.63113\n",
      "\n",
      "Epoch 75: val_loss improved from 0.63113 to 0.63066, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 76: val_loss improved from 0.63066 to 0.62968, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.62968\n",
      "\n",
      "Epoch 91: val_loss improved from 0.62968 to 0.62929, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 92: val_loss improved from 0.62929 to 0.62904, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.62904\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.62904\n",
      "\n",
      "Epoch 95: val_loss improved from 0.62904 to 0.62894, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 96: val_loss improved from 0.62894 to 0.62885, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.62885\n",
      "\n",
      "Epoch 98: val_loss improved from 0.62885 to 0.62786, saving model to ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.62786\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.62786\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68606, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68606 to 0.68285, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68285 to 0.67928, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.67928\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67928 to 0.67796, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67796 to 0.67555, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67555 to 0.67470, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67470 to 0.67373, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67373 to 0.67033, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67033 to 0.67018, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.67018 to 0.66834, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66834 to 0.66647, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: val_loss improved from 0.66647 to 0.66641, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.66641 to 0.66439, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.66439 to 0.66114, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.66114\n",
      "\n",
      "Epoch 17: val_loss improved from 0.66114 to 0.65963, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.65963 to 0.65822, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.65822 to 0.65766, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.65766\n",
      "\n",
      "Epoch 21: val_loss improved from 0.65766 to 0.65501, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.65501\n",
      "\n",
      "Epoch 23: val_loss improved from 0.65501 to 0.65250, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.65250 to 0.65125, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.65125 to 0.65032, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65032\n",
      "\n",
      "Epoch 27: val_loss improved from 0.65032 to 0.64927, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.64927\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.64927\n",
      "\n",
      "Epoch 30: val_loss improved from 0.64927 to 0.64762, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.64762\n",
      "\n",
      "Epoch 32: val_loss improved from 0.64762 to 0.64636, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.64636\n",
      "\n",
      "Epoch 34: val_loss improved from 0.64636 to 0.64549, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.64549 to 0.64395, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.64395 to 0.64378, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.64378\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.64378\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.64378\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.64378\n",
      "\n",
      "Epoch 41: val_loss improved from 0.64378 to 0.64059, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.64059\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.64059\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.64059\n",
      "\n",
      "Epoch 45: val_loss improved from 0.64059 to 0.64017, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss improved from 0.64017 to 0.64006, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.64006\n",
      "\n",
      "Epoch 48: val_loss improved from 0.64006 to 0.63979, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.63979 to 0.63942, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss improved from 0.63942 to 0.63903, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss improved from 0.63903 to 0.63824, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.63824\n",
      "\n",
      "Epoch 53: val_loss improved from 0.63824 to 0.63615, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.63615\n",
      "\n",
      "Epoch 60: val_loss improved from 0.63615 to 0.63429, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.63429\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.63429\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.63429\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.63429\n",
      "\n",
      "Epoch 65: val_loss improved from 0.63429 to 0.63364, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.63364\n",
      "\n",
      "Epoch 67: val_loss improved from 0.63364 to 0.63362, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.63362\n",
      "\n",
      "Epoch 69: val_loss improved from 0.63362 to 0.63159, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.63159\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.63159\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.63159\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.63159\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.63159\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.63159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76: val_loss improved from 0.63159 to 0.63041, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 77: val_loss improved from 0.63041 to 0.63007, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss improved from 0.63007 to 0.62953, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.62953\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.62953\n",
      "\n",
      "Epoch 81: val_loss improved from 0.62953 to 0.62938, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.62938\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.62938\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.62938\n",
      "\n",
      "Epoch 85: val_loss improved from 0.62938 to 0.62846, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 86: val_loss improved from 0.62846 to 0.62818, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.62818\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.62818\n",
      "\n",
      "Epoch 89: val_loss improved from 0.62818 to 0.62811, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 90: val_loss improved from 0.62811 to 0.62715, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.62715\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.62715\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.62715\n",
      "\n",
      "Epoch 94: val_loss improved from 0.62715 to 0.62653, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.62653\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.62653\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.62653\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.62653\n",
      "\n",
      "Epoch 99: val_loss improved from 0.62653 to 0.62619, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 100: val_loss improved from 0.62619 to 0.62600, saving model to ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68524, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68524 to 0.68295, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68295 to 0.68166, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68166 to 0.68094, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68094 to 0.67794, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67794 to 0.67759, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67759 to 0.67599, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67599 to 0.67274, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67274 to 0.67193, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67193 to 0.67111, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.67111 to 0.66966, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66966 to 0.66845, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.66845 to 0.66602, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.66602\n",
      "\n",
      "Epoch 15: val_loss improved from 0.66602 to 0.66290, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.66290\n",
      "\n",
      "Epoch 17: val_loss improved from 0.66290 to 0.65995, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.65995 to 0.65992, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.65992 to 0.65851, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.65851 to 0.65838, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.65838 to 0.65585, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.65585\n",
      "\n",
      "Epoch 23: val_loss improved from 0.65585 to 0.65394, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.65394 to 0.65325, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: val_loss improved from 0.65325 to 0.65293, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65293\n",
      "\n",
      "Epoch 27: val_loss improved from 0.65293 to 0.65232, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.65232 to 0.65108, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.65108\n",
      "\n",
      "Epoch 30: val_loss improved from 0.65108 to 0.64994, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.64994 to 0.64854, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.64854\n",
      "\n",
      "Epoch 33: val_loss improved from 0.64854 to 0.64720, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.64720\n",
      "\n",
      "Epoch 35: val_loss improved from 0.64720 to 0.64566, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.64566 to 0.64533, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.64533 to 0.64462, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.64462\n",
      "\n",
      "Epoch 39: val_loss improved from 0.64462 to 0.64451, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.64451 to 0.64213, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.64213\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.64213\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.64213\n",
      "\n",
      "Epoch 44: val_loss improved from 0.64213 to 0.64069, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.64069 to 0.64040, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.64040\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.64040\n",
      "\n",
      "Epoch 48: val_loss improved from 0.64040 to 0.63857, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.63857 to 0.63779, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.63779\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.63779\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.63779\n",
      "\n",
      "Epoch 53: val_loss improved from 0.63779 to 0.63686, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.63686\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.63686\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.63686\n",
      "\n",
      "Epoch 57: val_loss improved from 0.63686 to 0.63581, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.63581\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.63581\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.63581\n",
      "\n",
      "Epoch 61: val_loss improved from 0.63581 to 0.63428, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.63428\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.63428\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.63428\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.63428\n",
      "\n",
      "Epoch 66: val_loss improved from 0.63428 to 0.63394, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.63394\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.63394\n",
      "\n",
      "Epoch 69: val_loss improved from 0.63394 to 0.63280, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.63280\n",
      "\n",
      "Epoch 71: val_loss improved from 0.63280 to 0.63214, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss improved from 0.63214 to 0.63114, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.63114\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.63114\n",
      "\n",
      "Epoch 75: val_loss improved from 0.63114 to 0.63080, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 76: val_loss improved from 0.63080 to 0.63062, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 77: val_loss improved from 0.63062 to 0.63030, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.63030\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.63030\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.63030\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.63030\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.63030\n",
      "\n",
      "Epoch 83: val_loss improved from 0.63030 to 0.63000, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.63000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.63000\n",
      "\n",
      "Epoch 86: val_loss improved from 0.63000 to 0.62942, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.62942\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.62942\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.62942\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.62942\n",
      "\n",
      "Epoch 91: val_loss improved from 0.62942 to 0.62870, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 92: val_loss improved from 0.62870 to 0.62852, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.62852\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.62852\n",
      "\n",
      "Epoch 95: val_loss improved from 0.62852 to 0.62792, saving model to ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.62792\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.62792\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.62792\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.62792\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.62792\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68626, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68626 to 0.68435, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68435 to 0.68151, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68151 to 0.68007, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68007 to 0.67898, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67898 to 0.67841, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67841 to 0.67608, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67608 to 0.67323, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67323 to 0.67185, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67185 to 0.67085, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.67085 to 0.66980, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.66980\n",
      "\n",
      "Epoch 13: val_loss improved from 0.66980 to 0.66877, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.66877 to 0.66709, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.66709 to 0.66424, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.66424\n",
      "\n",
      "Epoch 17: val_loss improved from 0.66424 to 0.66382, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.66382 to 0.66163, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.66163 to 0.66073, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.66073 to 0.65950, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.65950 to 0.65846, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.65846 to 0.65727, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.65727 to 0.65547, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.65547 to 0.65496, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.65496 to 0.65356, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65356\n",
      "\n",
      "Epoch 27: val_loss improved from 0.65356 to 0.65220, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.65220 to 0.65158, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.65158 to 0.65069, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.65069\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.65069\n",
      "\n",
      "Epoch 32: val_loss improved from 0.65069 to 0.65006, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.65006 to 0.64833, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.64833 to 0.64830, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.64830 to 0.64727, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.64727 to 0.64703, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.64703 to 0.64690, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss improved from 0.64690 to 0.64651, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.64651 to 0.64622, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.64622 to 0.64519, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.64519\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.64519\n",
      "\n",
      "Epoch 43: val_loss improved from 0.64519 to 0.64481, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.64481\n",
      "\n",
      "Epoch 45: val_loss improved from 0.64481 to 0.64321, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.64321\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.64321\n",
      "\n",
      "Epoch 48: val_loss improved from 0.64321 to 0.64172, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.64172\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.64172\n",
      "\n",
      "Epoch 51: val_loss improved from 0.64172 to 0.64131, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss improved from 0.64131 to 0.64036, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.64036\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.64036\n",
      "\n",
      "Epoch 55: val_loss improved from 0.64036 to 0.64026, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.64026\n",
      "\n",
      "Epoch 57: val_loss improved from 0.64026 to 0.63996, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss improved from 0.63996 to 0.63893, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.63893\n",
      "\n",
      "Epoch 60: val_loss improved from 0.63893 to 0.63817, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss improved from 0.63817 to 0.63778, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.63778\n",
      "\n",
      "Epoch 63: val_loss improved from 0.63778 to 0.63714, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss improved from 0.63714 to 0.63700, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.63700\n",
      "\n",
      "Epoch 66: val_loss improved from 0.63700 to 0.63598, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.63598\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.63598\n",
      "\n",
      "Epoch 69: val_loss improved from 0.63598 to 0.63597, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.63597\n",
      "\n",
      "Epoch 71: val_loss improved from 0.63597 to 0.63585, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.63585\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.63585\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.63585\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.63585\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.63585\n",
      "\n",
      "Epoch 77: val_loss improved from 0.63585 to 0.63572, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.63572\n",
      "\n",
      "Epoch 79: val_loss improved from 0.63572 to 0.63538, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.63538\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.63538\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.63538\n",
      "\n",
      "Epoch 83: val_loss improved from 0.63538 to 0.63525, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.63525\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.63525\n",
      "\n",
      "Epoch 86: val_loss improved from 0.63525 to 0.63507, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.63507\n",
      "\n",
      "Epoch 88: val_loss improved from 0.63507 to 0.63421, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.63421\n",
      "\n",
      "Epoch 90: val_loss improved from 0.63421 to 0.63336, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.63336\n",
      "\n",
      "Epoch 92: val_loss improved from 0.63336 to 0.63158, saving model to ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.63158\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68575, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.68575 to 0.68429, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68429 to 0.68094, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68094 to 0.67892, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67892 to 0.67806, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67806 to 0.67677, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67677 to 0.67552, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67552 to 0.67274, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.67274 to 0.67081, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.67081 to 0.66812, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66812 to 0.66749, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66749 to 0.66657, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.66657 to 0.66568, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.66568 to 0.66294, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.66294 to 0.65999, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.65999\n",
      "\n",
      "Epoch 17: val_loss improved from 0.65999 to 0.65872, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.65872 to 0.65667, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.65667 to 0.65649, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.65649 to 0.65437, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.65437 to 0.65333, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.65333 to 0.65305, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.65305 to 0.65166, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.65166 to 0.65151, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.65151 to 0.65065, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65065\n",
      "\n",
      "Epoch 27: val_loss improved from 0.65065 to 0.64879, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.64879 to 0.64806, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.64806 to 0.64769, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.64769\n",
      "\n",
      "Epoch 31: val_loss improved from 0.64769 to 0.64761, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.64761 to 0.64568, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.64568 to 0.64507, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.64507\n",
      "\n",
      "Epoch 35: val_loss improved from 0.64507 to 0.64496, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.64496 to 0.64376, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.64376 to 0.64318, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss improved from 0.64318 to 0.64313, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.64313 to 0.64239, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.64239 to 0.64133, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.64133\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.64133\n",
      "\n",
      "Epoch 43: val_loss improved from 0.64133 to 0.64079, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss improved from 0.64079 to 0.64007, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.64007\n",
      "\n",
      "Epoch 46: val_loss improved from 0.64007 to 0.63811, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.63811\n",
      "\n",
      "Epoch 53: val_loss improved from 0.63811 to 0.63685, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.63685\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.63685\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.63685\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.63685\n",
      "\n",
      "Epoch 58: val_loss improved from 0.63685 to 0.63562, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.63562\n",
      "\n",
      "Epoch 60: val_loss improved from 0.63562 to 0.63552, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.63552\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.63552\n",
      "\n",
      "Epoch 63: val_loss improved from 0.63552 to 0.63540, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss improved from 0.63540 to 0.63451, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.63451\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.63451\n",
      "\n",
      "Epoch 67: val_loss improved from 0.63451 to 0.63314, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.63314\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.63314\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.63314\n",
      "\n",
      "Epoch 71: val_loss improved from 0.63314 to 0.63251, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss improved from 0.63251 to 0.63146, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.63146\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.63146\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.63146\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.63146\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.63146\n",
      "\n",
      "Epoch 78: val_loss improved from 0.63146 to 0.63038, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.63038\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.63038\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.63038\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.63038\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.63038\n",
      "\n",
      "Epoch 84: val_loss improved from 0.63038 to 0.62979, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.62979\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.62979\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.62979\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.62979\n",
      "\n",
      "Epoch 89: val_loss improved from 0.62979 to 0.62956, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.62956\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.62956\n",
      "\n",
      "Epoch 92: val_loss improved from 0.62956 to 0.62796, saving model to ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/64_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.62796\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68547, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68547 to 0.68232, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68232 to 0.68066, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68066 to 0.67952, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67952 to 0.67574, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67574 to 0.67346, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67346 to 0.67116, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67116 to 0.66945, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66945 to 0.66547, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66547 to 0.66061, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.66061\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66061 to 0.65592, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65592 to 0.65509, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.65509 to 0.65431, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65431 to 0.64820, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.64820\n",
      "\n",
      "Epoch 17: val_loss improved from 0.64820 to 0.64552, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.64552 to 0.64347, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.64347 to 0.64113, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.64113 to 0.63938, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.63938 to 0.63662, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.63662\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63662 to 0.63293, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.63293 to 0.63095, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.63095 to 0.63064, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.63064 to 0.62734, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.62734 to 0.62687, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.62687 to 0.62638, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.62638 to 0.62405, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.62405 to 0.62260, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.62260 to 0.62152, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.62152\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.62152\n",
      "\n",
      "Epoch 35: val_loss improved from 0.62152 to 0.61931, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.61931 to 0.61676, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.61676\n",
      "\n",
      "Epoch 38: val_loss improved from 0.61676 to 0.61600, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.61600 to 0.61491, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.61491 to 0.61448, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.61448\n",
      "\n",
      "Epoch 42: val_loss improved from 0.61448 to 0.61261, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.61261\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.61261\n",
      "\n",
      "Epoch 45: val_loss improved from 0.61261 to 0.61192, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss improved from 0.61192 to 0.61055, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.61055\n",
      "\n",
      "Epoch 48: val_loss improved from 0.61055 to 0.60998, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.60998 to 0.60931, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss improved from 0.60931 to 0.60829, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 53: val_loss improved from 0.60829 to 0.60766, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss improved from 0.60766 to 0.60729, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 55: val_loss improved from 0.60729 to 0.60521, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.60521\n",
      "\n",
      "Epoch 57: val_loss improved from 0.60521 to 0.60482, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: val_loss did not improve from 0.60482\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.60482\n",
      "\n",
      "Epoch 60: val_loss improved from 0.60482 to 0.60441, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss improved from 0.60441 to 0.60354, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss improved from 0.60354 to 0.60282, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 63: val_loss improved from 0.60282 to 0.60282, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.60282\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.60282\n",
      "\n",
      "Epoch 66: val_loss improved from 0.60282 to 0.60121, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.60121\n",
      "\n",
      "Epoch 75: val_loss improved from 0.60121 to 0.60017, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.60017\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.60017\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.60017\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.60017\n",
      "\n",
      "Epoch 80: val_loss improved from 0.60017 to 0.59790, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.59790\n",
      "\n",
      "Epoch 87: val_loss improved from 0.59790 to 0.59736, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss improved from 0.59736 to 0.59532, saving model to ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.59532\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68550, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68550 to 0.68083, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68083 to 0.67781, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67781 to 0.67778, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67778 to 0.67438, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67438 to 0.67191, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67191 to 0.66986, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66986 to 0.66771, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66771 to 0.66410, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66410 to 0.66207, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66207 to 0.65840, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65840 to 0.65660, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65660 to 0.65377, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.65377 to 0.65341, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65341 to 0.64794, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.64794 to 0.64701, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.64701 to 0.64605, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.64605 to 0.64274, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.64274\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.64274\n",
      "\n",
      "Epoch 21: val_loss improved from 0.64274 to 0.63941, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.63941 to 0.63756, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.63756 to 0.63661, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63661 to 0.63473, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.63473 to 0.63248, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.63248 to 0.62986, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.62986 to 0.62911, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.62911 to 0.62843, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.62843 to 0.62648, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.62648 to 0.62645, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.62645\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.62645\n",
      "\n",
      "Epoch 33: val_loss improved from 0.62645 to 0.62366, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.62366 to 0.62195, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.62195 to 0.62170, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.62170 to 0.62119, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.62119\n",
      "\n",
      "Epoch 38: val_loss improved from 0.62119 to 0.62010, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.62010\n",
      "\n",
      "Epoch 40: val_loss improved from 0.62010 to 0.61953, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss improved from 0.61953 to 0.61929, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss improved from 0.61929 to 0.61846, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss improved from 0.61846 to 0.61669, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.61669\n",
      "\n",
      "Epoch 45: val_loss improved from 0.61669 to 0.61645, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss improved from 0.61645 to 0.61547, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss improved from 0.61547 to 0.61427, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss improved from 0.61427 to 0.61279, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.61279 to 0.61254, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.61254\n",
      "\n",
      "Epoch 51: val_loss improved from 0.61254 to 0.61203, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.61203\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.61203\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.61203\n",
      "\n",
      "Epoch 55: val_loss improved from 0.61203 to 0.61201, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.61201\n",
      "\n",
      "Epoch 57: val_loss improved from 0.61201 to 0.60970, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.60970\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.60970\n",
      "\n",
      "Epoch 60: val_loss improved from 0.60970 to 0.60899, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.60899\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.60899\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.60899\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.60899\n",
      "\n",
      "Epoch 65: val_loss improved from 0.60899 to 0.60782, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.60782\n",
      "\n",
      "Epoch 67: val_loss improved from 0.60782 to 0.60685, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss improved from 0.60685 to 0.60660, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.60660\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.60660\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.60660\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.60660\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.60660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74: val_loss improved from 0.60660 to 0.60450, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.60450\n",
      "\n",
      "Epoch 82: val_loss improved from 0.60450 to 0.60277, saving model to ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.60277\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68583, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68583 to 0.68243, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68243 to 0.67934, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67934 to 0.67892, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67892 to 0.67662, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67662 to 0.67337, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67337 to 0.67092, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67092 to 0.66822, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66822 to 0.66464, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66464 to 0.66302, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66302 to 0.65926, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65926 to 0.65806, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65806 to 0.65549, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.65549 to 0.65335, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65335 to 0.65130, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.65130 to 0.64946, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.64946 to 0.64693, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.64693 to 0.64464, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.64464 to 0.64399, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.64399 to 0.64346, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.64346 to 0.64071, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.64071 to 0.63732, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.63732 to 0.63645, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63645 to 0.63417, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.63417 to 0.63306, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.63306 to 0.63174, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.63174 to 0.63166, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.63166 to 0.62971, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: val_loss did not improve from 0.62971\n",
      "\n",
      "Epoch 30: val_loss improved from 0.62971 to 0.62644, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.62644 to 0.62618, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.62618 to 0.62397, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.62397\n",
      "\n",
      "Epoch 34: val_loss improved from 0.62397 to 0.62334, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.62334 to 0.62070, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.62070\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.62070\n",
      "\n",
      "Epoch 38: val_loss improved from 0.62070 to 0.61839, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.61839\n",
      "\n",
      "Epoch 40: val_loss improved from 0.61839 to 0.61835, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.61835\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.61835\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.61835\n",
      "\n",
      "Epoch 44: val_loss improved from 0.61835 to 0.61716, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.61716 to 0.61612, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss improved from 0.61612 to 0.61495, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.61495\n",
      "\n",
      "Epoch 48: val_loss improved from 0.61495 to 0.61339, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.61339\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.61339\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.61339\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.61339\n",
      "\n",
      "Epoch 53: val_loss improved from 0.61339 to 0.61218, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.61218\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.61218\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.61218\n",
      "\n",
      "Epoch 57: val_loss improved from 0.61218 to 0.61189, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.61189\n",
      "\n",
      "Epoch 59: val_loss improved from 0.61189 to 0.61002, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.61002\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.61002\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.61002\n",
      "\n",
      "Epoch 63: val_loss improved from 0.61002 to 0.60830, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.60830\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.60830\n",
      "\n",
      "Epoch 66: val_loss improved from 0.60830 to 0.60515, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.60515\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.60515\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.60515\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.60515\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.60515\n",
      "\n",
      "Epoch 72: val_loss improved from 0.60515 to 0.60499, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.60499\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.60499\n",
      "\n",
      "Epoch 75: val_loss improved from 0.60499 to 0.60472, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 76: val_loss improved from 0.60472 to 0.60429, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 77: val_loss improved from 0.60429 to 0.60346, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.60346\n",
      "\n",
      "Epoch 79: val_loss improved from 0.60346 to 0.60118, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.60118\n",
      "\n",
      "Epoch 87: val_loss improved from 0.60118 to 0.60043, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.60043\n",
      "\n",
      "Epoch 95: val_loss improved from 0.60043 to 0.59995, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 96: val_loss improved from 0.59995 to 0.59976, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.59976\n",
      "\n",
      "Epoch 98: val_loss improved from 0.59976 to 0.59905, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 99: val_loss improved from 0.59905 to 0.59866, saving model to ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_3_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: val_loss did not improve from 0.59866\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68450, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68450 to 0.68265, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68265 to 0.68016, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68016 to 0.67718, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67718 to 0.67533, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67533 to 0.67387, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67387 to 0.67068, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.67068 to 0.66729, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66729 to 0.66429, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66429 to 0.66141, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66141 to 0.65998, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65998 to 0.65849, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65849 to 0.65578, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.65578 to 0.65346, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65346 to 0.65016, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.65016 to 0.64898, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.64898 to 0.64672, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.64672 to 0.64438, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.64438 to 0.64249, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.64249 to 0.64124, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.64124 to 0.63770, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.63770 to 0.63700, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.63700 to 0.63639, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63639 to 0.63583, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.63583 to 0.63571, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.63571 to 0.63274, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.63274 to 0.63175, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.63175 to 0.63080, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.63080 to 0.62900, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.62900\n",
      "\n",
      "Epoch 31: val_loss improved from 0.62900 to 0.62898, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.62898 to 0.62714, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.62714 to 0.62710, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.62710 to 0.62402, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.62402\n",
      "\n",
      "Epoch 36: val_loss improved from 0.62402 to 0.62370, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.62370 to 0.62278, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.62278\n",
      "\n",
      "Epoch 39: val_loss improved from 0.62278 to 0.62169, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.62169\n",
      "\n",
      "Epoch 41: val_loss improved from 0.62169 to 0.62140, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss improved from 0.62140 to 0.61803, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.61803\n",
      "\n",
      "Epoch 44: val_loss improved from 0.61803 to 0.61691, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.61691\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.61691\n",
      "\n",
      "Epoch 47: val_loss improved from 0.61691 to 0.61685, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss improved from 0.61685 to 0.61656, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.61656 to 0.61641, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.61641\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.61641\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.61641\n",
      "\n",
      "Epoch 53: val_loss improved from 0.61641 to 0.61419, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.61419\n",
      "\n",
      "Epoch 55: val_loss improved from 0.61419 to 0.61418, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.61418\n",
      "\n",
      "Epoch 57: val_loss improved from 0.61418 to 0.61407, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.61407\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.61407\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.61407\n",
      "\n",
      "Epoch 61: val_loss improved from 0.61407 to 0.61275, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.61275\n",
      "\n",
      "Epoch 63: val_loss improved from 0.61275 to 0.61157, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.61157\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.61157\n",
      "\n",
      "Epoch 66: val_loss improved from 0.61157 to 0.60995, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.60995\n",
      "\n",
      "Epoch 68: val_loss improved from 0.60995 to 0.60935, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.60935\n",
      "\n",
      "Epoch 70: val_loss improved from 0.60935 to 0.60869, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 71: val_loss improved from 0.60869 to 0.60846, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.60846\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.60846\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.60846\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.60846\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.60846\n",
      "\n",
      "Epoch 77: val_loss improved from 0.60846 to 0.60828, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.60828\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.60828\n",
      "\n",
      "Epoch 80: val_loss improved from 0.60828 to 0.60812, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.60812\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.60812\n",
      "\n",
      "Epoch 83: val_loss improved from 0.60812 to 0.60632, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.60632\n",
      "\n",
      "Epoch 94: val_loss improved from 0.60632 to 0.60453, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.60453\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.60453\n",
      "\n",
      "Epoch 97: val_loss improved from 0.60453 to 0.60373, saving model to ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.60373\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.60373\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.60373\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68421, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68421 to 0.68338, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68338 to 0.67846, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67846 to 0.67776, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67776 to 0.67625, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_loss improved from 0.67625 to 0.67348, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67348 to 0.66984, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66984 to 0.66648, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66648 to 0.66501, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66501 to 0.66171, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66171 to 0.66061, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.66061 to 0.65851, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65851 to 0.65463, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.65463 to 0.65379, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.65379 to 0.65077, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.65077 to 0.64899, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.64899 to 0.64666, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.64666\n",
      "\n",
      "Epoch 19: val_loss improved from 0.64666 to 0.64253, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.64253 to 0.64251, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.64251 to 0.63909, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.63909 to 0.63607, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.63607 to 0.63492, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.63492 to 0.63458, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.63458 to 0.63382, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.63382\n",
      "\n",
      "Epoch 27: val_loss improved from 0.63382 to 0.63013, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.63013 to 0.62898, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.62898 to 0.62669, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.62669\n",
      "\n",
      "Epoch 31: val_loss improved from 0.62669 to 0.62622, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.62622 to 0.62575, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.62575 to 0.62395, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.62395 to 0.62323, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.62323 to 0.62304, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.62304 to 0.62215, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.62215\n",
      "\n",
      "Epoch 38: val_loss improved from 0.62215 to 0.62178, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.62178 to 0.62047, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.62047 to 0.61953, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss improved from 0.61953 to 0.61814, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.61814\n",
      "\n",
      "Epoch 43: val_loss improved from 0.61814 to 0.61797, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.61797\n",
      "\n",
      "Epoch 45: val_loss improved from 0.61797 to 0.61738, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46: val_loss improved from 0.61738 to 0.61657, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.61657\n",
      "\n",
      "Epoch 48: val_loss improved from 0.61657 to 0.61486, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.61486 to 0.61460, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.61460\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.61460\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.61460\n",
      "\n",
      "Epoch 53: val_loss improved from 0.61460 to 0.61156, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.61156\n",
      "\n",
      "Epoch 55: val_loss improved from 0.61156 to 0.61083, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.61083\n",
      "\n",
      "Epoch 57: val_loss improved from 0.61083 to 0.61072, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.61072\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.61072\n",
      "\n",
      "Epoch 60: val_loss improved from 0.61072 to 0.60979, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 61: val_loss improved from 0.60979 to 0.60950, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss improved from 0.60950 to 0.60829, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.60829\n",
      "\n",
      "Epoch 67: val_loss improved from 0.60829 to 0.60636, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.60636\n",
      "\n",
      "Epoch 74: val_loss improved from 0.60636 to 0.60580, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.60580\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.60580\n",
      "\n",
      "Epoch 77: val_loss improved from 0.60580 to 0.60531, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss improved from 0.60531 to 0.60504, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 79: val_loss improved from 0.60504 to 0.60412, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 80: val_loss improved from 0.60412 to 0.60357, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 81: val_loss improved from 0.60357 to 0.60351, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.60351\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.60351\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.60351\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.60351\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.60351\n",
      "\n",
      "Epoch 87: val_loss improved from 0.60351 to 0.60338, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.60338\n",
      "\n",
      "Epoch 89: val_loss improved from 0.60338 to 0.60217, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.60217\n",
      "\n",
      "Epoch 91: val_loss improved from 0.60217 to 0.60169, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 92: val_loss improved from 0.60169 to 0.60096, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.60096\n",
      "\n",
      "Epoch 94: val_loss improved from 0.60096 to 0.60027, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.60027\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.60027\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.60027\n",
      "\n",
      "Epoch 98: val_loss improved from 0.60027 to 0.59917, saving model to ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/128_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.59917\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.59917\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68532, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68532 to 0.68198, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68198 to 0.67897, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67897 to 0.67867, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67867 to 0.67254, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67254 to 0.66988, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.66988 to 0.66462, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66462 to 0.65985, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.65985 to 0.65489, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65489 to 0.64996, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.64996 to 0.64730, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.64730 to 0.64475, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.64475 to 0.63794, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.63794\n",
      "\n",
      "Epoch 15: val_loss improved from 0.63794 to 0.63258, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.63258 to 0.63035, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.63035 to 0.62894, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.62894 to 0.62570, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62570 to 0.62196, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.62196\n",
      "\n",
      "Epoch 21: val_loss improved from 0.62196 to 0.62053, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.62053 to 0.61538, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.61538 to 0.61406, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.61406 to 0.61313, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.61313 to 0.61045, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.61045\n",
      "\n",
      "Epoch 27: val_loss improved from 0.61045 to 0.61029, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.61029 to 0.60704, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.60704\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60704 to 0.60301, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.60301\n",
      "\n",
      "Epoch 32: val_loss improved from 0.60301 to 0.60180, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.60180\n",
      "\n",
      "Epoch 34: val_loss improved from 0.60180 to 0.59989, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.59989 to 0.59830, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.59830 to 0.59663, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.59663\n",
      "\n",
      "Epoch 38: val_loss improved from 0.59663 to 0.59509, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.59509 to 0.59366, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.59366 to 0.59334, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.59334\n",
      "\n",
      "Epoch 42: val_loss improved from 0.59334 to 0.59205, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.59205\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.59205\n",
      "\n",
      "Epoch 45: val_loss improved from 0.59205 to 0.59141, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.59141\n",
      "\n",
      "Epoch 47: val_loss improved from 0.59141 to 0.58917, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.58917\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.58917\n",
      "\n",
      "Epoch 50: val_loss improved from 0.58917 to 0.58715, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss improved from 0.58715 to 0.58557, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.58557\n",
      "\n",
      "Epoch 53: val_loss improved from 0.58557 to 0.58524, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: val_loss did not improve from 0.58524\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.58524\n",
      "\n",
      "Epoch 56: val_loss improved from 0.58524 to 0.58292, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.58292\n",
      "\n",
      "Epoch 58: val_loss improved from 0.58292 to 0.58245, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 59: val_loss improved from 0.58245 to 0.58155, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.58155\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.58155\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.58155\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.58155\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.58155\n",
      "\n",
      "Epoch 65: val_loss improved from 0.58155 to 0.58035, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.58035\n",
      "\n",
      "Epoch 67: val_loss improved from 0.58035 to 0.57820, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.57820\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.57820\n",
      "\n",
      "Epoch 70: val_loss improved from 0.57820 to 0.57787, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.57787\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.57787\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.57787\n",
      "\n",
      "Epoch 74: val_loss improved from 0.57787 to 0.57697, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.57697\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.57697\n",
      "\n",
      "Epoch 77: val_loss improved from 0.57697 to 0.57674, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.57674\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.57674\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.57674\n",
      "\n",
      "Epoch 81: val_loss improved from 0.57674 to 0.57559, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.57559\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.57559\n",
      "\n",
      "Epoch 84: val_loss improved from 0.57559 to 0.57548, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 85: val_loss improved from 0.57548 to 0.57544, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.57544\n",
      "\n",
      "Epoch 87: val_loss improved from 0.57544 to 0.57414, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss improved from 0.57414 to 0.57383, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.57383\n",
      "\n",
      "Epoch 90: val_loss improved from 0.57383 to 0.57352, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.57352\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.57352\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.57352\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.57352\n",
      "\n",
      "Epoch 95: val_loss improved from 0.57352 to 0.57216, saving model to ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_1_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.57216\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.57216\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.57216\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.57216\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.57216\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68451, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68451 to 0.68100, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68100 to 0.67696, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67696 to 0.67618, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67618 to 0.67113, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67113 to 0.66856, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.66856 to 0.66482, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66482 to 0.65972, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.65972 to 0.65707, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65707 to 0.65387, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65387 to 0.64922, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.64922 to 0.64611, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.64611 to 0.64452, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.64452 to 0.63785, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.63785 to 0.63555, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.63555 to 0.63432, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.63432 to 0.63017, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.63017 to 0.62701, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62701 to 0.62670, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.62670 to 0.62450, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.62450 to 0.62089, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.62089 to 0.61779, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.61779 to 0.61562, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.61562\n",
      "\n",
      "Epoch 25: val_loss improved from 0.61562 to 0.61354, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.61354 to 0.61091, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.61091 to 0.61081, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.61081 to 0.60949, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.60949 to 0.60691, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60691 to 0.60587, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.60587 to 0.60506, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.60506\n",
      "\n",
      "Epoch 33: val_loss improved from 0.60506 to 0.60292, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.60292 to 0.60211, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.60211 to 0.60097, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.60097\n",
      "\n",
      "Epoch 37: val_loss improved from 0.60097 to 0.59992, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.59992\n",
      "\n",
      "Epoch 39: val_loss improved from 0.59992 to 0.59768, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.59768 to 0.59639, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss improved from 0.59639 to 0.59561, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss improved from 0.59561 to 0.59442, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.59442\n",
      "\n",
      "Epoch 44: val_loss improved from 0.59442 to 0.59370, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.59370 to 0.59117, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.59117\n",
      "\n",
      "Epoch 47: val_loss improved from 0.59117 to 0.58985, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.58985\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.58985\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.58985\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.58985\n",
      "\n",
      "Epoch 52: val_loss improved from 0.58985 to 0.58718, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.58718\n",
      "\n",
      "Epoch 54: val_loss improved from 0.58718 to 0.58629, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.58629\n",
      "\n",
      "Epoch 56: val_loss improved from 0.58629 to 0.58567, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.58567\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.58567\n",
      "\n",
      "Epoch 59: val_loss improved from 0.58567 to 0.58329, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.58329\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.58329\n",
      "\n",
      "Epoch 62: val_loss improved from 0.58329 to 0.58151, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 63: val_loss improved from 0.58151 to 0.58139, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.58139\n",
      "\n",
      "Epoch 65: val_loss improved from 0.58139 to 0.58075, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.58075\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.58075\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.58075\n",
      "\n",
      "Epoch 69: val_loss improved from 0.58075 to 0.57929, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.57929\n",
      "\n",
      "Epoch 76: val_loss improved from 0.57929 to 0.57899, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 77: val_loss improved from 0.57899 to 0.57779, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.57779\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.57779\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.57779\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.57779\n",
      "\n",
      "Epoch 82: val_loss improved from 0.57779 to 0.57576, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.57576\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.57576\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.57576\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.57576\n",
      "\n",
      "Epoch 87: val_loss improved from 0.57576 to 0.57537, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.57537\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.57537\n",
      "\n",
      "Epoch 90: val_loss improved from 0.57537 to 0.57534, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.57534\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.57534\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.57534\n",
      "\n",
      "Epoch 94: val_loss improved from 0.57534 to 0.57421, saving model to ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_2_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.57421\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68431, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68431 to 0.68152, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68152 to 0.67896, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67896 to 0.67572, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67572 to 0.67203, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67203 to 0.66808, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.66808 to 0.66446, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66446 to 0.66096, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66096 to 0.65503, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65503 to 0.65498, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65498 to 0.65036, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65036 to 0.64747, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.64747 to 0.64357, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.64357 to 0.64023, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.64023 to 0.63742, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.63742 to 0.63685, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.63685 to 0.63174, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.63174 to 0.62728, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62728 to 0.62685, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.62685 to 0.62156, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.62156 to 0.62143, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.62143 to 0.61780, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.61780\n",
      "\n",
      "Epoch 24: val_loss improved from 0.61780 to 0.61501, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.61501 to 0.61299, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.61299 to 0.61176, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.61176 to 0.61037, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.61037 to 0.60761, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.60761 to 0.60732, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60732 to 0.60583, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.60583\n",
      "\n",
      "Epoch 32: val_loss improved from 0.60583 to 0.60419, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.60419\n",
      "\n",
      "Epoch 34: val_loss improved from 0.60419 to 0.59966, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.59966\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.59966\n",
      "\n",
      "Epoch 37: val_loss improved from 0.59966 to 0.59756, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.59756\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.59756\n",
      "\n",
      "Epoch 40: val_loss improved from 0.59756 to 0.59746, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.59746\n",
      "\n",
      "Epoch 42: val_loss improved from 0.59746 to 0.59449, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.59449\n",
      "\n",
      "Epoch 44: val_loss improved from 0.59449 to 0.59392, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.59392 to 0.59187, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.59187\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.59187\n",
      "\n",
      "Epoch 48: val_loss improved from 0.59187 to 0.59187, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss improved from 0.59187 to 0.59028, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.59028\n",
      "\n",
      "Epoch 51: val_loss improved from 0.59028 to 0.58921, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.58921\n",
      "\n",
      "Epoch 53: val_loss improved from 0.58921 to 0.58915, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.58915\n",
      "\n",
      "Epoch 55: val_loss improved from 0.58915 to 0.58742, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.58742\n",
      "\n",
      "Epoch 57: val_loss improved from 0.58742 to 0.58610, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.58610\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.58610\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.58610\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.58610\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.58610\n",
      "\n",
      "Epoch 63: val_loss improved from 0.58610 to 0.58536, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss improved from 0.58536 to 0.58445, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.58445\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.58445\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.58445\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.58445\n",
      "\n",
      "Epoch 69: val_loss improved from 0.58445 to 0.58289, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.58289\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.58289\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.58289\n",
      "\n",
      "Epoch 73: val_loss improved from 0.58289 to 0.58078, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.58078\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.58078\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.58078\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.58078\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.58078\n",
      "\n",
      "Epoch 79: val_loss improved from 0.58078 to 0.58062, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 80: val_loss improved from 0.58062 to 0.58052, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81: val_loss improved from 0.58052 to 0.58049, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.58049\n",
      "\n",
      "Epoch 83: val_loss improved from 0.58049 to 0.57947, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.57947\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.57947\n",
      "\n",
      "Epoch 86: val_loss improved from 0.57947 to 0.57910, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 87: val_loss improved from 0.57910 to 0.57794, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.57794\n",
      "\n",
      "Epoch 89: val_loss improved from 0.57794 to 0.57722, saving model to ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_3_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.57722\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68464, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68464 to 0.68299, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68299 to 0.67991, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67991 to 0.67703, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67703 to 0.67397, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67397 to 0.67273, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67273 to 0.66753, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66753 to 0.66484, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.66484 to 0.66133, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.66133 to 0.65658, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65658 to 0.65341, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65341 to 0.65213, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.65213 to 0.64633, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.64633 to 0.64454, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.64454 to 0.64094, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.64094 to 0.63683, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.63683 to 0.63506, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.63506 to 0.63234, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.63234 to 0.62925, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.62925 to 0.62713, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.62713 to 0.62506, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.62506 to 0.62443, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.62443 to 0.62075, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.62075 to 0.62059, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.62059 to 0.61796, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.61796\n",
      "\n",
      "Epoch 27: val_loss improved from 0.61796 to 0.61718, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.61718 to 0.61556, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: val_loss improved from 0.61556 to 0.61356, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.61356 to 0.61294, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.61294\n",
      "\n",
      "Epoch 32: val_loss improved from 0.61294 to 0.60915, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.60915\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.60915\n",
      "\n",
      "Epoch 35: val_loss improved from 0.60915 to 0.60819, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss improved from 0.60819 to 0.60727, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.60727 to 0.60615, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss improved from 0.60615 to 0.60402, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.60402\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.60402\n",
      "\n",
      "Epoch 41: val_loss improved from 0.60402 to 0.60185, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 42: val_loss improved from 0.60185 to 0.60052, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 43: val_loss improved from 0.60052 to 0.59829, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss improved from 0.59829 to 0.59671, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.59671\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.59671\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.59671\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.59671\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.59671\n",
      "\n",
      "Epoch 50: val_loss improved from 0.59671 to 0.59529, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.59529\n",
      "\n",
      "Epoch 52: val_loss improved from 0.59529 to 0.59430, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 53: val_loss improved from 0.59430 to 0.59407, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.59407\n",
      "\n",
      "Epoch 55: val_loss improved from 0.59407 to 0.59301, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.59301\n",
      "\n",
      "Epoch 57: val_loss improved from 0.59301 to 0.59232, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.59232\n",
      "\n",
      "Epoch 59: val_loss improved from 0.59232 to 0.59117, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.59117\n",
      "\n",
      "Epoch 61: val_loss improved from 0.59117 to 0.59076, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.59076\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.59076\n",
      "\n",
      "Epoch 64: val_loss improved from 0.59076 to 0.58971, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.58971\n",
      "\n",
      "Epoch 66: val_loss improved from 0.58971 to 0.58907, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.58907\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.58907\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.58907\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.58907\n",
      "\n",
      "Epoch 71: val_loss improved from 0.58907 to 0.58825, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss improved from 0.58825 to 0.58744, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.58744\n",
      "\n",
      "Epoch 81: val_loss improved from 0.58744 to 0.58672, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss improved from 0.58672 to 0.58560, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.58560\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.58560\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.58560\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.58560\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.58560\n",
      "\n",
      "Epoch 88: val_loss improved from 0.58560 to 0.58498, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 89: val_loss improved from 0.58498 to 0.58498, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.58498\n",
      "\n",
      "Epoch 91: val_loss improved from 0.58498 to 0.58404, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 92: val_loss improved from 0.58404 to 0.58388, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.58388\n",
      "\n",
      "Epoch 94: val_loss improved from 0.58388 to 0.58229, saving model to ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_4_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.58229\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68364, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68364 to 0.68204, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68204 to 0.67798, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67798 to 0.67475, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67475 to 0.67162, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67162 to 0.67063, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.67063 to 0.66501, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.66501 to 0.65911, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.65911 to 0.65678, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.65678 to 0.65091, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.65091 to 0.64874, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.64874 to 0.64331, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.64331 to 0.64073, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.64073 to 0.63746, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.63746 to 0.63209, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.63209 to 0.62838, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.62838 to 0.62599, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.62599\n",
      "\n",
      "Epoch 19: val_loss improved from 0.62599 to 0.62189, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.62189 to 0.61968, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.61968 to 0.61853, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.61853 to 0.61683, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.61683 to 0.60989, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.60989 to 0.60871, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.60871\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.60871\n",
      "\n",
      "Epoch 27: val_loss improved from 0.60871 to 0.60221, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.60221\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.60221\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.60221\n",
      "\n",
      "Epoch 31: val_loss improved from 0.60221 to 0.60051, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.60051 to 0.59931, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss improved from 0.59931 to 0.59783, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 34: val_loss improved from 0.59783 to 0.59597, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.59597\n",
      "\n",
      "Epoch 36: val_loss improved from 0.59597 to 0.59568, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 37: val_loss improved from 0.59568 to 0.59439, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.59439\n",
      "\n",
      "Epoch 39: val_loss improved from 0.59439 to 0.59229, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.59229 to 0.59129, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.59129\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.59129\n",
      "\n",
      "Epoch 43: val_loss improved from 0.59129 to 0.59121, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 44: val_loss improved from 0.59121 to 0.58991, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.58991 to 0.58742, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.58742\n",
      "\n",
      "Epoch 47: val_loss improved from 0.58742 to 0.58718, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss improved from 0.58718 to 0.58661, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.58661\n",
      "\n",
      "Epoch 50: val_loss improved from 0.58661 to 0.58605, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss improved from 0.58605 to 0.58521, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss improved from 0.58521 to 0.58500, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.58500\n",
      "\n",
      "Epoch 54: val_loss improved from 0.58500 to 0.58404, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 55: val_loss improved from 0.58404 to 0.58353, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss improved from 0.58353 to 0.58185, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 57: val_loss improved from 0.58185 to 0.58154, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss improved from 0.58154 to 0.58031, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.58031\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.58031\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.58031\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.58031\n",
      "\n",
      "Epoch 63: val_loss improved from 0.58031 to 0.57910, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.57910\n",
      "\n",
      "Epoch 65: val_loss improved from 0.57910 to 0.57871, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.57871\n",
      "\n",
      "Epoch 67: val_loss improved from 0.57871 to 0.57734, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.57734\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.57734\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.57734\n",
      "\n",
      "Epoch 71: val_loss improved from 0.57734 to 0.57721, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.57721\n",
      "\n",
      "Epoch 80: val_loss improved from 0.57721 to 0.57602, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 81: val_loss improved from 0.57602 to 0.57516, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 82: val_loss improved from 0.57516 to 0.57447, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.57447\n",
      "\n",
      "Epoch 92: val_loss improved from 0.57447 to 0.57265, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.57265\n",
      "\n",
      "Epoch 94: val_loss improved from 0.57265 to 0.57255, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.57255\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.57255\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.57255\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.57255\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.57255\n",
      "\n",
      "Epoch 100: val_loss improved from 0.57255 to 0.57225, saving model to ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3a/256_units_5_fold_/best_epoch_weights/assets\n"
     ]
    }
   ],
   "source": [
    "# perform experiments\n",
    "err,accuracy,last_epoch_times,histories = train_exp(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11d0c7",
   "metadata": {},
   "source": [
    "## a) Plot the mean cross-validation accuracies on the final epoch for different\n",
    "numbers of hidden-layer neurons using a scatter plot. Limit the search space of the\n",
    "number of neurons to {64, 128, 256}.\n",
    "3\n",
    "Continue using 5-fold cross validation on training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d88f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean cross validation accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(hidden_units, accuracy, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(hidden_units)\n",
    "plt.xlabel('hidden_units')\n",
    "plt.ylabel('mean cross validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ec6de",
   "metadata": {},
   "source": [
    "## b) Select the optimal number of neurons for the hidden layer. State the rationale for your selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34087170",
   "metadata": {},
   "source": [
    "256 is the best number of neurons to use for the first hidden layer as it has the highest cross validation accuracy among all the batch sizes tried"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d118e9",
   "metadata": {},
   "source": [
    "## c) Plot the train and test accuracies against training epochs with the optimal number of neurons using a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43553f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68352, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.68352 to 0.68139, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss improved from 0.68139 to 0.67975, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 4: val_loss improved from 0.67975 to 0.67208, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.67208 to 0.67002, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss improved from 0.67002 to 0.66393, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 7: val_loss improved from 0.66393 to 0.65784, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 8: val_loss improved from 0.65784 to 0.65091, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.65091 to 0.64658, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.64658 to 0.64653, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss improved from 0.64653 to 0.63730, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 12: val_loss improved from 0.63730 to 0.63289, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 13: val_loss improved from 0.63289 to 0.62824, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.62824 to 0.62580, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss improved from 0.62580 to 0.62305, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 16: val_loss improved from 0.62305 to 0.61783, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.61783 to 0.61426, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss improved from 0.61426 to 0.61302, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 19: val_loss improved from 0.61302 to 0.60993, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 20: val_loss improved from 0.60993 to 0.60820, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 21: val_loss improved from 0.60820 to 0.60441, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 22: val_loss improved from 0.60441 to 0.60087, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 23: val_loss improved from 0.60087 to 0.60027, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 24: val_loss improved from 0.60027 to 0.59839, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 25: val_loss improved from 0.59839 to 0.59798, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss improved from 0.59798 to 0.59483, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 27: val_loss improved from 0.59483 to 0.59438, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.59438 to 0.59100, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss improved from 0.59100 to 0.58934, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 30: val_loss improved from 0.58934 to 0.58923, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 31: val_loss improved from 0.58923 to 0.58733, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss improved from 0.58733 to 0.58570, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.58570\n",
      "\n",
      "Epoch 34: val_loss improved from 0.58570 to 0.58398, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 35: val_loss improved from 0.58398 to 0.58160, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.58160\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.58160\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.58160\n",
      "\n",
      "Epoch 39: val_loss improved from 0.58160 to 0.57870, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss improved from 0.57870 to 0.57600, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.57600\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.57600\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.57600\n",
      "\n",
      "Epoch 44: val_loss improved from 0.57600 to 0.57595, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 45: val_loss improved from 0.57595 to 0.57456, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.57456\n",
      "\n",
      "Epoch 47: val_loss improved from 0.57456 to 0.57192, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.57192\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.57192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: val_loss improved from 0.57192 to 0.57175, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 51: val_loss improved from 0.57175 to 0.57058, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 52: val_loss improved from 0.57058 to 0.56955, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.56955\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.56955\n",
      "\n",
      "Epoch 55: val_loss improved from 0.56955 to 0.56811, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 56: val_loss improved from 0.56811 to 0.56703, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 57: val_loss improved from 0.56703 to 0.56689, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.56689\n",
      "\n",
      "Epoch 59: val_loss improved from 0.56689 to 0.56501, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.56501\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.56501\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.56501\n",
      "\n",
      "Epoch 63: val_loss improved from 0.56501 to 0.56260, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 64: val_loss improved from 0.56260 to 0.56193, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.56193\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.56193\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.56193\n",
      "\n",
      "Epoch 68: val_loss improved from 0.56193 to 0.56098, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 69: val_loss improved from 0.56098 to 0.55925, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.55925\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.55925\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.55925\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.55925\n",
      "\n",
      "Epoch 74: val_loss improved from 0.55925 to 0.55898, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 75: val_loss improved from 0.55898 to 0.55859, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.55859\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.55859\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.55859\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.55859\n",
      "\n",
      "Epoch 80: val_loss improved from 0.55859 to 0.55852, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.55852\n",
      "\n",
      "Epoch 82: val_loss improved from 0.55852 to 0.55755, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.55755\n",
      "\n",
      "Epoch 84: val_loss improved from 0.55755 to 0.55716, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 85: val_loss improved from 0.55716 to 0.55706, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 86: val_loss improved from 0.55706 to 0.55588, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 87: val_loss improved from 0.55588 to 0.55545, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.55545\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.55545\n",
      "\n",
      "Epoch 90: val_loss improved from 0.55545 to 0.55529, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.55529\n",
      "\n",
      "Epoch 92: val_loss improved from 0.55529 to 0.55462, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.55462\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.55462\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.55462\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.55462\n",
      "\n",
      "Epoch 97: val_loss improved from 0.55462 to 0.55429, saving model to ./data/models/PartA_Q3c/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3c/best_epoch_weights/assets\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.55429\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.55429\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.55429\n"
     ]
    }
   ],
   "source": [
    "model_path = './data/models/PartA_Q3c/best_epoch_weights'\n",
    "\n",
    "optimum_model = build_model((X_train_scaled.shape[1],),\n",
    "                            128,\n",
    "                            256,\n",
    "                            0.2)\n",
    "history,timecallbackinstance = compile_and_train(optimum_model,\n",
    "                            no_epochs= 100,\n",
    "                            lr= 0.001,\n",
    "                            batch_size=128,\n",
    "                            x_train= X_train_scaled,\n",
    "                            y_train = y_train,\n",
    "                            x_test = X_test_scaled,\n",
    "                            y_test = y_test,\n",
    "                            model_path=model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7252c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden units 256\n",
    "doc_histories={}\n",
    "doc_histories[\"optimum_model\"] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6097acc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEHCAYAAAC5u6FsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAABGLElEQVR4nO3dd3xUVfr48c+TOumNUEJCD0F6E1BEQVdFwYYNdi3sqliw7te67rquq/vVr+76c3ddd7F3VFwUFDvGLk2Q3lsSWkhIrzPz/P6YIQyBQAKZTMrzfr3yytxzyzz3MMyTe88954iqYowxxtRXUKADMMYY07JY4jDGGNMgljiMMcY0iCUOY4wxDWKJwxhjTINY4jDGGNMgIf48uIiMB54CgoHnVPXRWuufBMZ5FyOB9qoa713nAlZ4121X1fO95d2BmUASsAS4UlWrjhRHfHy89urVq1HOqaUrLS0lKioq0GE0G1YfB7P6OMDqApYsWbJXVZNrl4u/+nGISDCwHjgTyAYWAVNUdXUd298CDFHV33iXS1Q1+jDbvQ38V1Vnisi/gZ9V9ZkjxZKRkaHr1q07vhNqJTIzMxk7dmygw2g2rD4OZvVxgNUFiMgSVR1eu9yft6pGABtVdbP3imAmcMERtp8CvHmkA4qIAKcDs7xFLwMXHn+oxhhj6sufiaMzkOWznO0tO4SIdAW6A/N9ih0islhEfhSRC71lSUCBqjqPdkxjjDH+4dc2jgaYDMxSVZdPWVdVzRGRHsB8EVkBFNb3gCIyDZgGkJycTGZmZmPG22KVlJRYXfiw+jiY1ccBVhd182fiyAHSfJZTvWWHMxmY7lugqjne35tFJBMYArwLxItIiPeqo85jquoMYAZ42jhq36usrq4mOzubioqKhp1VCxcXF4fD4Qh0GM3GsdSHw+EgNTWV0NBQP0UVOHZf/wCri7r5M3EsAtK9T0Hl4EkOv6y9kYj0ARKAH3zKEoAyVa0UkXbAaOD/VFVF5EvgEjxtJlcD7x9LcNnZ2cTExNCtWzc8TSdtQ3FxMTExMYEOo9loaH2oKnl5eWRnZ9O9e3c/RmZM8+W3Ng7vFcHNwCfAGuBtVV0lIg+JyPk+m04GZurBj3edACwWkZ+BL4FHfZ7Gugf4rYhsxNPm8fyxxFdRUUFSUlKbShrm+IkISUlJbe5K1Rhffm3jUNV5wLxaZQ/UWn7wMPt9Dwyo45ib8TyxddwsaZhjYZ8b09Y1l8ZxY4wxTUBVKatyUVRRTXGFk+KKakoqXZRWOimpdFJe5aKsykV5tavOY1jiMMaYFsztVvJKq8gtrmRviecnr6SKvNIq8ksryS+tYl9ZNQVlVRSUVVNYXo3TfXwdvy1xBFB2djbTp09n9erVuN1uJk6cyOOPP05YWFid+xQUFPDGG29w0003AbBjxw5uvfVWZs2aVec+TWHq1Km8/fbb7N69u6ax+fbbb+epp54iNzeXdu3a1es4Dz74INHR0dx5550N2uaRRx7hnXfeAWDFihUMGOC50/mb3/yGW2+99ajve+211/Lb3/6Wvn371itOY5pCpdPFzoIKdhSWs7Oggp2F5ewqqmBXYSW7iyrYU1zB3pIqXIdJBKHBQmJUGIlR4SREhtKnYyxxkaHER4QSFxFKbEQoMY4QYhyhRIcHEx0eSmRYsPcnhPCQIIIfO3xcljgCRFWZNGkSN954I++//z4ul4tp06Zx//338/jjj9e5X0FBAf/6179qEkdKSkrAk8Z+vXr14v333+eKK67A7XYzf/58Ondumv6Z999/P/fffz8A0dHRLFu27KD1qoqqEhR0+OdBnnvuOX+HaMwh3G5lV1EF2/LKyMovY7v3J2tfGTn7ytlTXHnIPvGRoXSMddAh1kGfjjG0jw2nfYyD5Jhw2kWH0y46jKTocGIdIX5rj7PEAfxp7ipW7yhq1GP2TYnlj+f1q3P9/PnzcTgc/PrXvwYgODiYJ598ku7du/OnP/2Jt99+m9mzZ1NYWEhOTg5XXHEFf/zjH7n33nvZtGkTgwcP5swzz2T69OlMnDiRlStX8tJLL/Hee+9RWlrKhg0buPPOO6mqquLVV18lPDycefPmERoaytixY3niiScYPnw4e/fuZfjw4WzdurVe+ycmJtZ5TpMnT+att97iiiuuIDMzk9GjR/PRRx/VrP/b3/7GCy+8AHj+wr/99tsBz9XCyy+/TPv27UlLS2PYsGEAbNq0ienTp5Obm0tkZCTPPvssffr0qfe/wdatWzn77LMZOXIkS5YsYd68eTz66KMsWrSI8vJyLrnkkpqrFt86iY6O5rbbbuODDz4gIiKC999/nw4dOtT7fY2prbCsmo25xWzKLWVzbimbc0vYmlfKtrwyKp3umu1CgoSU+AjSEiMYm5FMakIkKfERpMQ56BQfQac4B47Q4ACeiTfOQAfQVq1atarmC3K/2NhYunTpwsaNGwFYuHAhK1euJDIykhNPPJEJEybw6KOPsnLlypq/qLdu3XrQMVauXMnSpUupqKigV69ePPbYYyxdupQ77riDV155hWuuueaIcR1t//1f9ofTu3dv5syZw759+3jzzTe54oorahLHkiVLePHFF1mwYAGqysiRIznttNNwu93MnDmTZcuW4XQ6GTp0aE29TJs2jX//+9+kp6ezYMECbrrpJubPn1/n+x/Ohg0bePnllxk1ahTgSVKJiYm4XC7OOOMMxo8fz0knnXTQPqWlpYwaNYpHHnmEu+++m2effZbf//73DXpf0zbtK61i/e5i1u8pYcPuYjbsLmFjbgm5PlcOocFC16QouiVFcVrvZLq187zukhhJpzgHIcHNf7YLSxxwxCuDQDrzzDNJSkoCYNKkSXz77bdceOGFR9xn3LhxxMTEEBMTQ1xcHOeddx4AAwYMYPny5Ud9z+Pdf9KkScycOZMFCxbwn//8p6b822+/5aKLLqoZpnrSpEl88803uN1uLrroIiIjIwE4/3xPF5+SkhK+//57Lr300ppjVFYeetl+NF27dq1JGgBvv/02M2bMwOl0snPnTtauXXtI4ggLC2PixIkADBs2jM8++6zB72tat5JKJxt2F3uSxO4S1u8uZu2u4oMSRHR4CL3aR3Na72R6tY+mV3I0PdtHk5YQ0SKSw5FY4giQvn37HtI2UVRUxPbt2+nVqxc//fTTIfcn63O/Mjw8vOZ1UFBQzXJQUBBOp2dsyJCQENxuz+Vx7Y5s9dn/SC6//HKGDRvG1VdfXWd7Qn243W7i4+MPaatoKN/5FLZs2cITTzzBokWLSEhIYOrUqYdNRqGhoTV1HRwcXK/zNq1TcUU1G/eU1PzsTxQ5BeU12zhCg+jdIYbTeifTu0M06R1i6N0hhpQ4R6vt82OJI0DOOOMM7r33Xl555RWuuuoqXC4X//M//8PUqVNr/vr+7LPPyM/PJyIigvfee48XXniBmJgYiouLj+u9u3XrxpIlSxgxYkSjN6x37dqVRx55hF/84hcHlY8ZM4apU6dy7733oqrMnj2bV199FVVl6tSp3HfffTidTubOncv1119PbGws3bt355133uHSSy9FVVm+fDmDBg065tiKioqIiooiLi6O3bt389FHHx10NWLapopqF9n7ytiWV8aWvaVs2etph1iTU0bBx5/WbBcWHESP5CiGdU1g8olpZHSMIaNjDGkJkQQFtc4EURdLHAEiIsyePZubbrqJP//5z7jdbs4991z+8pe/1GwzYsQILr74YrKzs7niiisYPtwzn8ro0aPp378/55xzDtOnT6/rLep05513ctlllzFjxgwmTJjQaOe03/XXX39I2dChQ5k6dSojRng6/V977bUMGTIE8FylDBo0iPbt23PiiSfW7PP6669z44038vDDD1NdXc3kyZOPK3EMGjSIIUOG0KdPH9LS0hg9evQxH8u0HG63sqe4kqx9ZWTvKyMrv9zz5JL3Z2dRBb4DHsVFhNIjOYp+ScGMHtiTXsnR9GofTZfEyBZ/i6mx+G0GwObkcDMArlmzhhNOOCFAER3dSy+9xOLFi/nnP//ZqMe1QQ4Pdqz10dw/P8eqJY4Iq6rsLanyJoZysvI9v7O9yzn7yqlyuQ/ap0NsOF0SI0lLiKRLUqSncdr7OzHK04+qJdZFY6trBkC74jDGNHvVLjfZ+8rZmlfK9jzPbaXt+aXeK4fyQ4bHSIwKIy0hgr6dYjmrXwfSEiJJTYggLTGSzvERzeKR1pbMEkczNXXqVKZOnRroMA4xffp0vvvuu4PKbrvttpr+KMYcj+KKatbvLmHTHs9jrBv3lLBlbylZ+WUHDZMRERpMl8RIuiZFcUqvZLokRpCaEElaoidBRIXbV5s/We2aBnn66acDHYJpBVSVnYUVrMgpZFVOIat3FrF2VzHZ+w48rRQWEkSPdlGc0CmGc/p3pHu7KLq1i6JrUiTJ0eGt9omllsAShzHG70ornfycVcDSrAKWbt/H0u0F5JVWARAk0DM5miFdEpgyogsZHWJI7xBNakIkwW3saaWWwhKHMabR7SutYsGWfBZt9fys2lFUMxBfz+Qoxma0Z1BaHP07x3FCx1giwqzNoSWxxGGMOW6eRJHHj5vz+XFzHmt3efoahYcEMTgtnhtP68nwbgkMSUsgLrL1zdXe1ljiMMY0WEFZFQu35PPj5nx+2JzH2l1FqHp6UQ/vmsidZ3ViVI8kBqTGER5iVxOtjfVmCaDs7GwuuOAC0tPT6dmzJ7fddhtVVVVH3Gf/sOr77dixg0suucTfoR7V/h7vvr3ab7/9dkSEvXv31vs4Dz74IE888USDt/nqq68OGXPK6XTSoUMHduzYcdjjZGZmHjQWlqnb3pJKPlqxkwfnrOLcp75hyJ8/Y9qrS3h9wTbiI0K54xe9eeeGk1j+x7N57dqR3Hx6OsO7JVrSaKX8esUhIuOBp4Bg4DlVfbTW+ieBcd7FSKC9qsaLyGDgGSAWcAGPqOpb3n1eAk4DCr37TVXVZf48D3+w+Tga15gxY8jOzmbbtm107doVgM8//5x+/fqRkpLSJDG0Fm63sim3hCXb9rF42z6WbNvHlr2lgOeKYljXBG4/ozcn9UxiUJpdUbRFfkscIhIMPA2cCWQDi0Rkjqqu3r+Nqt7hs/0twBDvYhlwlapuEJEUYImIfKKqBd71d6lqo35bXv6fHw4pmziwE1ee1I3yKhdTX1x4yPpLhqVy6fA08kuruPG1JQete+v6kw7Z3pfNx9G483EEBQVx2WWXMXPmTO655x4AZs6cyZQpU1i4cCG33XYbFRUVRERE8OKLL5KRkXHEf5+2ZE9RBT9nF/JzVgFfLi/nli8/pbjSM7BjQmQow7omcvmJaYzonkj/lDjCQuxGRVvnzyuOEcBGVd0MICIzgQuA1XVsPwX4I4Cqrt9fqKo7RGQPkAwU+DHeJmXzcTT+fBxTpkzhuuuu45577qGyspJ58+bxt7/9jZCQEL755htCQkL4/PPP+d3vfse77757xHporfaVVrE8p5AV2QUszy5keXYhu4o8IyQHBwmp0cL5g1MY0iWBIV3i6dEuyvpLmEP4M3F0BrJ8lrOBkYfbUES6At2BQ74VRGQEEAZs8il+REQeAL4A7lXVQ8bGFpFpwDSA5ORkMjMzD1ofFxd30P34537Z/7AnsX+bI60PPcz6o41gW1FRQVVV1SHbud1uSktLqaioYOzYsYSFheF0OpkwYQKff/45EydOxO121+xXUlJSs1xRUcEpp5wCgMPhIDY2lnHjxlFcXEx6ejorV67E5XLhcrkoLS2luLiYkpISVLXe+9d1XtXV1ZSXlzNhwgReeuklfvjhB5544glUlZKSEj7//HPOPffcmuHcJ0yYwGeffVYzuKPL5UJEGD9+PJWVlezcuZPvv/+eiy++uOY9KisrKS4uprKyktDQ0ENiycjIoKioiJ9++ol169YxbNgwQkNDyc7O5u6772bTpk2ICNXV1RQXF1NWVlZz7g1VUVFxyGequSl3KlsL3WwpdLGlyM2WQjd7yw/0vu4YKXSLC2JcShg94oLoEhtEdXkp0dF5UJxH1qqD/wO3NSUlJc3+3zhQmstTVZOBWap60IAzItIJeBW4WlX3j1J2H7ALTzKZAdwDPFT7gKo6w7uejIwMrT1Y2Zo1awI62N/QoUP54IMPDoqhqKiI7OxsBg0axLp16wgLC6tZHx4eTkREBNHR0QQFBdWU+y47HA6io6Nr1gUHB5OUlERMTAyRkZEEBQURHBxcc6yYmBgKCwsRkXrvX1edhYaGEhERwVVXXVUzH0dcXBwiQnR0NA6Hg/Dw8IPOx+Fw4Ha7DyoPCwsjPDycqKgo4uPjDzt5VHh4+EH7+PrVr37F3LlzWbNmDVdeeSUxMTE89thjnHnmmcydO5etW7cyduzYmnPaf+4N5XA4akb3bQ5cbmXDnmKWbi/gp237WJZVwMbc0ppRX9MSIxjZK56BqXEM6BxH/9Q4Yh2HPhZrA/sdYHVRN38mjhwgzWc51Vt2OJOBg8YHF5FY4EPgflX9cX+5qu70vqwUkReBOxst4iZk83H4Zz6OKVOmcP7551NYWMjzzz8PQGFhYU0j/UsvvdSo5xsoZVVOlm0vYNHWfSzels/S7QWU+LRLDE6LZ+LAFAalxTEwNb5mxFdjGoM/E8ciIF1EuuNJGJOBX9beSET6AAnADz5lYcBs4JXajeAi0klVd4rnxuuFwEq/nYEf2Xwc/pmP44QTTiAqKophw4bVzP539913c/XVV/Pwww/75XybQmmlk0VbPf0mFm7JY3l2IU63IgIZHWK4YHAKw7omMKRLAt2SIq1dwviVX+fjEJFzgf+H53HcF1T1ERF5CFisqnO82zwIOFT1Xp/9rgBeBFb5HG6qqi4Tkfl4GsoFWAbcoKolR4rD5uM4wObjOFhznY+jyulm6fZ9fLdxL99vymNZVgFOtxISJAxMjWNkjyRGdEtkaNcE4iIarye23Z45wOoiQPNxqOo8YF6tsgdqLT94mP1eA16r45inN2KIxjQLqsqm3FK+Xp/LNxtyWbAln7IqF0ECA1Pjue7UHpzcM4lhXROIDGsuTZOmrbJPYDNl83G0fqWVTr7buJcv1+Xy9fpccgo8Q4r3aBfFJcNSOaVXO0b1TDpsI7YxgdSmE4eq2r3gBrL5ODyfm2OVlV/GF2t288XaPSzYnE+Vy01UWDCje7XjpnE9OTU9mbTEyEaM1pjG12YTh8PhIC8vj6SkJEsept5Ulby8PBwOR723X7WjiE9X7eLT1btrRo3tkRzFVSd15fQ+7RneLdF6Y5sWpc0mjtTUVLKzs8nNzQ10KE2qoqKi3l96bcGx1IfD4SA1NbXO9W63sjRrH/NW7OKTVbvI3ldOkMDwroncf+4JnHFCe3okRx9v6MYETJtNHKGhoXTv3j3QYTS5zMzMZtVxLdAaqz72J4u5P+/k45W72FVUQVhwEKekt+OW03vxixM6kBQd3ggRGxN4bTZxGHO89t+GmvvzDj5YvpOcgnLCQoI4rXcy9w7owxkntCfGGrZNK2SJw5gG2pZXypxlO3hvWQ6bcksJCRLGpLfjf87qzZl9O1iyMK2eJQ5j6iGvpJIPV+xk9tIclm4vAGBE90R+c0p3zu3fiQQb0sO0IZY4jKlDRbWLz9fsZvZPOXy1PhenW+nTMYZ7xvfhgsEppMRHBDpEYwLCEocxPtxuZdHWfGYvzeHDFTsprnDSMdbBNad058IhnTmhU2ygQzQm4CxxGANszi1h9tIcZi/NIXtfOVFhwYzv34lJQzszqkcSwUHW18eY/SxxmDarsKya+dur+fu/vuOn7QUECZySnsydZ2VwVr8ONiaUMXWw/xmmTXG63HyzYS+zlmTz2erdVLncZHQI53fn9uGCwZ3pEGudI405Gkscpk3YlFvCO4uzefenbHKLK0mMCuOXI7vQTXdx9fljbNgZYxrAEodptcqrXHywfAdvLcpi8bZ9BAcJ4zKSuXR4GuMy2hMWEkRmZq4lDWMayBKHaXXW7CzijQXbeW9ZDsUVTnq0i+Lec/owaWhn2sfYrShjjpclDtMqVDpdfLRiF6/+uI0l2/YRFhLEhAGdmHxiGiO6J9pVhTGNyBKHadF2F1Xw6g/beHPhdvJKq+iWFMnvJ5zAJcNSiY+03tymeaqodlFS6aSs0kX72HAcocHsKChn9Y4iKp1uqlwuqp1KlcvNeQNTiIsMZUV2Id9u3IvbOx+MqqIKV4/uRqwj1DMn/aa8mvfY/7fStWN64AgN5vtNe1m6vaBmPpn908pMH9eLoCBh/trdLMsqrDluv5S6+yz5NXGIyHjgKTxzjj+nqo/WWv8kMM67GAm0V9V477qrgd971z2sqi97y4cBLwEReKalvU39OXG6aZZ+zirg+W+3MG/FTlyqnNGnA1ef3JXRPdsRZH0uTAAUllWzLLuAvJJK9pZUkldSRV5pFdeN6UFGxxjmr93N3bNWUFRRTZXTXbPf7JtOZkiXBL7dsJe7311+yHFP7JZIXKQnMTz28dpD1k8alkqsI5QfN+Xx18/WH7L+ylHdcIQG8/X6vfz7q02HrL9hbE+CEOav3cNrP25HBIJEuHho5zrPVfz1nSsiwcB64EwgG1gETFHV1XVsfwswRFV/IyKJwGJgOKDAEmCYqu4TkYXArcACPInj76r60ZFiycjI0HXr1jXSmbVsmZmZjB07NtBhHBO3W8lcv4d/f7WZhVvyiQkP4bIT07j6pG50STq2WfNacn34g9WHh9Pl5sPPv6LPoOEkRIXSPsbBnqIKXvx+K3uLK8ktqWRPkef3g+f1Y8LATvy4OY/JM36sOUZYSBBJUWE8cekgRvdqx6odhby+YDsxjhBiHaFEh4cQFR7C2Ixk2kWHk1dSSU5BOeEhwYSFBBEaLIQFB5EYFUZIcBBVTjcutyLiuZoQhCCB4CBBRHC79cDViM+5hHjXO11u3N4V+69GhAP7H25GVBFZoqrDa9ePP684RgAbVXWzN4CZwAXAYRMHMAX4o/f12cBnqprv3fczYLyIZAKxqvqjt/wV4ELgiInDtGxOl5sPlu/kX5kbWb+7hJQ4B7+fcAKTR3QhOtzutppDud1KcaWT4opqwkKCaB/joNrl5sPlOymuqKaowklxhWf9mPRkxvfvyN6SSi5+5nv2lVZRVOH0HOjLr/nduX2YdmpPyqtdPPfNZtpFh9MuOpxOcQ4GpsbRMc4zz0q/lFhm3XAS7aLDSYoOIzo85KAv4n4pcfzlogF1xpwUHX7EOVuONktkUJAQRN1X2yHBR96/Ie2A/vxf1xnI8lnOBkYebkMR6Qp0B+YfYd/O3p/sw5SbVqjK6ebdn7J5JnMT2/PLyOgQw/+7fDATBnYi9Cj/CUzrtGhrPnuKKskrrWRvSRX7Sqvo0ymGX43sCsDpf81kb3ElxZXOmnv4V47qyp8v7A/A7W8tqzlWWHAQMY6QmsEqo8JCGJQaT2JUGPGRoezN2caoIf3onxIHQJfESNY/fE6dX7AxjlCGd0v005k3L83lz7XJwCxVdTXWAUVkGjANIDk5mczMzMY6dItWUlLS7OvC6Va+y3EyZ1M1eRVK97ggbh0SzuD2LoIKN/DdNxsa7b1aQn00paasD7cqJdVQ6VSSIz1/CHy+rZodJW4KKpWCSqWwUukaG8StQz2PUf82s4z8igM3YqJCYUTHEDqXbwGgm6OSHhEQGRpKZIgQGQqp7CYzcy8Aj46JwBECkSFCWPD+BJBNZqbn79FJnQ7EV5JUSXT+erbmw1b/VkWL48/EkQOk+SynessOZzIwvda+Y2vtm+ktT61VfthjquoMYAZ42jjsvq1Hc76H7XIr7y3N4akvNrA9v4pBafH89RfpnNY72W+P0zbn+giExqgPVc9tot2FFewuqqS0ysnZ/ToC8NdP1/Htxr3sKapkT3EF1S7PUPUf334qAP945ns255XQPiaCzu3DGRwTzoDOcYwd7Znm+cWeBThCg0mMCiMhMvSQ2y+N+U9pn426+TNxLALSRaQ7ni/3ycAva28kIn2ABOAHn+JPgL+ISIJ3+SzgPlXNF5EiERmFp3H8KuAffjwH0wRUlcx1uTz28VrW7iqmX0osz189nNP7tLf+F82MqpJXWsXOggp2FJazq7CCvJJKfntWBgAPzV3Nmwu3U1594OZBXERoTeKoqHYRFRbCyO5RdIhz0CEm/KAHG96+/qQjjkQ8KC3ePydmGsRviUNVnSJyM54kEAy8oKqrROQhYLGqzvFuOhmY6ftIrTdB/BlP8gF4aH9DOXATBx7H/QhrGG/RVuYU8vCHq/lxcz5dkyL5x5QhTBjQyR6pDRC3KjsKysnKLyN7Xzk5BeVk7yvjT+f3JyIsmEc/Xst/vtp80D6hwcJN43rhCA1mQGosIl3oGOugfWw4HWIddPQZOPL+CX2P+P42fH3L4Nc2DlWdh+eRWd+yB2otP1jHvi8ALxymfDHQv/GiNIGwp7iCJz5ZxztLskmIDONP5/djyoguR31yxBy/SqeLrPwytuwtY1teKdvyyrhpXE86xUXwxTYnv/lk/kHbJ8eEc0tJJWmJkfzihA50inXQKT6ClLgIOsY5SIoKq0n0Fw1J5aIhgTgr05SaS+O4aSOqnG5e/G4Lf/9iA1UuN9eN6cHNp/ci1hEa6NBanYKyKtbvLmH97mJG92pH93ZRfLFmN9e+shjf7lsxjhAuGJxCp7gI+rYL5uEL+9MlMZLUhAhS4iNwhAbXbHtit0RObCNPDpm6WeIwTeaHTXn84f2VbNxTwi9OaM/9E/rSvV1UoMNq8VxupdLpIjIshKz8Mn43ewVrdxWTW1xZs83/ThpA93ZRZHSM4ZbT0+neLpJuSVF0S4oiPjK0pi2pc3QQY0d1DdSpmBbCEofxu7ySSh7+cA2zl+aQmhDB81cP54wTOgQ6rBZJVcneV85P2/exLKuAFdmFrNpRxHVjuvPbszKIiwxlX1kVp/VOpneHaNI7xNC7QwydvO0MqQmR/PbM3gE+C9PSWeIwfqOqvLcsh4fmrqak0smtp/eqaUQ19VPpdLEyp4jyKhenpLfDrTD+/31NaZULR2gQ/VPimDwijVE9kgCIdYTywS1jAhy1ae0scRi/yCko577/ruDr9bkM6RLPYxcPpHeHmECH1SIs2prPN+tzWbAln2VZBVQ63fTtFMu828YQHCQ8eflgOidEkNEh5qjDSBjjD5Y4TKNSVd5Zks2f567Gpcqfzu/HFaO62mOWdSgsr2bJtnxW5RRxyxnpALz0/VY+WrGT/p3juGJUV07slsiwrgk1+5zl7RNhTKBY4jCNZk9RBff9dwVfrN3DyO6JPH7JoGMetbY1W55dwH9/ymHBlnzW7ipC1dMXYsrILrSLDuf3E07gsYsH2gCOptmyT6ZpFJ+t3s3ds36mrMrFAxP7MvXkbm2+E1+l08WqHUUs3V7AsqwCbj29F+kdYticW8pbi7IY1jWB28/ozYjuiQxOiycizNP20ykuIsCRG3NkljjMcSmvcvHwh6t5fcF2+qXE8tTkIfRqHx3osJqc0+WmyuUmMiyEjXtKuOOtZazdVUS1y9NhIiXOwY7CCtI7xHDOgI5MHNjJ2idMi2WJwxyzdbuKmf7GT2zcU8L1p/bgt2f1Jjyk9T8x5XYra3YVsTKnkBU5hazIKWLtziKmj+vFrWekkxwdTowjhN+c0p0hafEMTkugY9yBYTfaQh2Z1s0Shzkmby/O4oH3VxIdHspr14zklPR2gQ7JL9xuZVNuCcuyCogIC2biwBTcqlz8zPdUVLuJDg+hX0osV47qysjunh7VcZGhvHHdqABHboz/WOIwDVJW5eQP763i3Z+yGd0riScvH0z7GMfRd2xhnvtmM1+u28PyrEKKKz2zwY3qkcjEgSmEBAcx48rhpCVG0jUxss235Zi2xxKHqbdteaVc/+oS1u0u5vZfpHPL6ekt/jHbwkrlw+U7WbAlj6z8Ml789QgAlmYVUFBWzQVDUhiclsDgtHh6+AyPcmrv5ECFbEzAWeIw9fLluj3c9uZSgoKEl389osV/cb63NIenv9zIhj1lwE9EhgUzrGsCFdUuHKHB/HPKEJsLxJg6WOIwR6SqPP3lRv762XpO6BjLf64cRlpiy+mb4XS5+Tm7kG825PLNhr08dvFAerWPJiRY6BQfwZD4Sqb84kT6d447aB5zSxrG1M0Sh6lTRbWLu2YtZ+7PO7hwcAr/O2lgTV+D5i4rv4xHP1rLNxtyKapwIgIDU+MpLK8GYOLAFCYOTCEzM5MhXRKOcjRjjC9LHOawdhdVMO2VxSzPKeSe8X244bQezfavcKfLzdKsAr5cu4f0DtFcNCSV2IhQlmUVML5/R07tncwpvdoRHxkW6FCNaRUscZhDrN5RxG9eWkRRRTX/uWJYsx0bae7PO/h09W6+Xp9LYXk1wUHC1JO7cdEQzzzX394zrtkmO2NaMksc5iDfbMjlxtd+Ijo8hFk3nEzflNhAhwR42lo27ClhZU4hk4amAvD6gm3eSaE6cHqf9pyS3o64iAMzCVrSMMY//Jo4RGQ88BQQDDynqo8eZpvLgAcBBX5W1V+KyDjgSZ/N+gCTVfU9EXkJOA0o9K6bqqrL/HYSbcisJdnc++5yerWP5sVfnxjwMZOcLjcLt+bz+eo9fL5mN9vzywgJEs7s24EYRyhP/3IoCZFh1o/CmCbmt8QhIsHA08CZQDawSETmqOpqn23SgfuA0aq6T0TaA6jql8Bg7zaJwEbgU5/D36Wqs/wVe1ujqvwrcxOPf7KO0b2SeOaKYQGbA7yi2oWIZ1iOl3/Yxp8/WE1YSBCn9GrHjWN7cnqf9sR4Y0uKDg9IjMa0df684hgBbFTVzQAiMhO4AFjts811wNOqug9AVfcc5jiXAB+papkfY22zVJX//WgtM77ezAWDU3j8kkGEhTTt4HtVTjffbsxl7s87+Wz1bh65qD8XDO7MhAGd6Bwfwam92xEZZndVjWku/Pm/sTOQ5bOcDYystU1vABH5Ds/trAdV9eNa20wG/lar7BEReQD4ArhXVSsbLeo2xOVW7p+9gpmLsrjqpK48eF6/Jr3tU1Ht4pEP1zB3+Q4KyqqJdYRw7oCO9Ez2jK7bMc7B+Ljm2TBvTFsmquqfA4tcAoxX1Wu9y1cCI1X1Zp9tPgCqgcuAVOBrYICqFnjXdwKWAymqWu1TtgsIA2YAm1T1ocO8/zRgGkBycvKwt99+2y/n2dKUlJQQHR2N063MWF7Jwl0uzusZyqReoU3SmFxSpWwvdtM3KRhV5aEfKugQJYzqFEL/dsGENHF7xf76MB5WHwdYXcC4ceOWqOrw2uVHveIQkfOAD1XV3cD3zAHSfJZTvWW+soEF3qSwRUTWA+nAIu/6y4DZ+5MGgKru9L6sFJEXgTsP9+aqOgNPYiEjI0PHjh3bwPBbp8zMTEaPOZVb3ljKwl27+N25fZh2ak+/v+/PWQW88sM25i7fQWiQsPj3Y4kIC+a00zSgjduZmZnYZ+MAq48DrC7qVp+b2ZcDG0Tk/0SkTwOOvQhIF5HuIhKG55bTnFrbvAeMBRCRdnhuXW32WT8FeNN3B+8VB+L58/hCYGUDYmrznG7l5jd+4uNVu3hgYl+/J43l2QVc9u8fuODp7/h45U4uHZbKrBtPrumBbk9EGdPyHPWKQ1WvEJFYPF/iL4mIAi8Cb6pq8RH2c4rIzcAneNovXlDVVSLyELBYVed4150lIqsBF56npfIARKQbniuWr2od+nURSQYEWAbc0JATbsuqnG6eXlbJ0j1l/PG8vvx6dHe/vE+1y01ppZP4yDBCgoLIKSjnDxP7ctnw1JonoowxLVe9GsdVtUhEZgERwO3ARcBdIvJ3Vf3HEfabB8yrVfaAz2sFfuv9qb3vVjwN7LXLT69PzOZgLrdyx1vLWLrHxYPn9WWqH5JGtcvNu0uyeTpzI0O7JPDU5CH0TYnl67vHtfjh140xB9SnjeN84NdAL+AVYISq7hGRSDyP1taZOEzzoKr87r8r+HDFTi7PCGv0pOF2K3OX7+Cvn65ne34ZA1PjuGBwSs16SxrGtC71ueK4GHhSVb/2LVTVMhG5xj9hmcaiqjz84RreWpzFraf3YmjYzqPv1EDPfOXpPHhCp1henHoiYzOSbbgPY1qx+iSOB4GabxsRiQA6qOpWVf3CX4GZxvGP+Rt5/tstTD25G3ec2ZuvvmqcxLFuVzEut9I3JZbLhqeRmhDBeQNTrLHbmDagPk9VvQP4Porr8paZZu7txVn87bP1TBramQcm9m2Uq4D80irun72Cc576mkc/XgtAckw4FwzubEnDmDaiPlccIapatX9BVau8j9eaZuyr9bn87r8rGJPejscuHnjcX+out/Lmwu08/sk6SiqdXHVSN247I72RojXGtCT1SRy5InK+9/FZROQCYK9/wzLHY2VOITe9toT0DjH861dDD5oS9Vi9vTiL37+3kpN6JPHQBf1I7xDTCJEaY1qi+iSOG/D0nfgnnr4TWcBVfo3KHLNdhRX85qVFxEaE8uLUE4+r30RRRTXb88ro3zmOSUM7kxgVxll9O1jDtzFtXH06AG4CRolItHe5xO9RmWNSUe1i2quLKa108u5NJ9MxznFMx1FVPlq5iwfnrCI0OIjMu8YSHhLM2c10JkBjTNOqVwdAEZkA9AMc+//aPNzAgiZwVJW7Zy1nRU4hM64cTp+OxzZz357iCv7w3ko+WbWbfimx/O+kAY1yq8sY03rUpwPgv4FIYBzwHJ75MRb6OS7TQM98tYk5P+/grrMzOLNvh2M6xva8Ms5/+lvKqlzce04frj2lOyGWNIwxtdTniuNkVR0oIstV9U8i8lfgI38HZurvy7V7ePyTdZw3KIWbxjZ80EKXWwkOEtISI5h8YhcuHZ5aMyeGMcbUVp8/Jyu8v8tEJAXP/Bmd/BeSaYis/DJuf2sZJ3SM5f8uHtjghutPV+3ijL9mkpVfhohw7zl9LGkYY46oPlccc0UkHngc+AlQ4Fl/BmXqp9LpYvobP+FW5ZkrhtYMVV4fpZVOHpyzineWZNMvJZZqV0OnWzHGtFVHTBwiEgR84Z2R713vjH0OVS1siuDMkT38wRqWZxfynyuH0TUpqt77rdpRyC1vLGVLXinTx/XktjN6N/k848aYluuIiUNV3SLyNDDEu1wJ2PzezcD7y3J49cdtTDu1R4Mfk33tx22UVjl5/dqRnNyznZ8iNMa0VvW5VfWFiFwM/Ff9NUG5aZBteaX87r8rGN41gbvOzqjXPiWVTvaVekaO+cPEvtx5VgZJ0eH+DNMY00rVJ3Fcj2eiJaeIVODpPa6qemwdBcxxcbrc3P7WMoKChKemDKlXH4uNe4q5/tUlBAcJ9w5WIsNCiAyrVxceY4w5xFG/dVQ1RlWDVDVMVWO9y5Y0AuQf8zeydHsBf7loAJ3jI466/bwVOzn/n99RWF7Ng+f3I8iGCzHGHKf6dAA89XDltSd2Mv63ZFs+/5i/gUlDO3PeoJQjbquq/GP+Rv722XqGdInnmV8No2Ocg8ysJgrWGNNq1ed+xV0+rx3ACGAJcNS5v0VkPPAUEAw8p6qPHmaby/BMFqXAz6r6S2+5C1jh3Wy7qp7vLe8OzASSvHFc6Tvse2tVXFHNbTOX0Tkhgj+d3++o21e53Hyxdg+ThnTmfy8eQHhI/R/VNcaYI6nPIIfn+S6LSBrw/462n4gEA08DZwLZwCIRmaOqq322SQfuA0ar6j4Rae9ziHJVHXyYQz+GZyrbmd7hUK4BnjlaPC3dX+atZUdBOe/ccNIRR7zNK6kkPDSY6PAQXr92JFFhwTaarTGmUR3Lw/vZwAn12G4EsFFVN3uvCGYCF9Ta5jrgaVXdB6Cqe450QPF8A54OzPIWvQxcWP/QW6bvNu7lzYXbueaU7gzrmljndln5ZVz8zPfcPnMZANHhIZY0jDGNrj5tHP/AcxsJPIlmMJ4e5EfTGc/cHftlAyNrbdPb+x7f4bmd9aCqfuxd5xCRxYATeFRV38Nze6pAVZ0+x+xcR9zTgGkAycnJZGZm1iPk5qfCqfz+u3I6RAonOnaTmXn43LqtyMXfllTidCu/6uWu83xLSkpabF34g9XHwaw+DrC6qFt92jgW+7x2Am+q6neN+P7pwFggFfhaRAZ4e6p3VdUcEekBzBeRFUC9e6yr6gxgBkBGRoaOHTu2kUJuWn98fyV5Fdt4+/qTOLHb4a82Fm7J54mXFhHtCOeV34w44ux8mZmZtNS68Aerj4NZfRxgdVG3+iSOWUCFqrrA03YhIpGqWnaU/XKANJ/lVG+Zr2xggapWA1tEZD2eRLJIVXMAVHWziGTi6b3+LhAvIiHeq47DHbPVWLA5j5d/2MbUk7vVmTSqXW7umvUz7WPDefWakaTU4xFdY4w5HvVp4/gC8P02igA+r8d+i4B0EekuImHAZGBOrW3ew3O1gYi0w3PrarOIJIhIuE/5aGC1t+f6l3jmBAG4Gni/HrG0OFVON7+bvYK0xAjuHl937/DQ4CCev/pEZk47yZKGMaZJ1CdxOHyni/W+jjzaTt4rgpuBT4A1wNuqukpEHhKR872bfQLkichqPAnhLlXNw9P4vlhEfvaWP+rzNNY9wG9FZCOeNo/n63OiLc2z32xmU24pD13Q/7C9vL9en8v/fbwWVaVX+2iSY2z4EGNM06jPrapSERmqqj8BiMgwoLw+B1fVecC8WmUP+LxWPMOZ/LbWNt8DA+o45mY8T2y1Wln5Zfz9iw2c078j4zLaH7J+4ZZ8rntlMT2So5k+rhdR4TZ8iDGm6dTnG+d24B0R2YFnnKqOwOX+DKotU1X+OGcVwUHCHyb2PWT9ypxCrnlpEZ0TInjtmhGWNIwxTa4+HQAXiUgfYP+N9nXexmzjB5+u3s38tXu4/9wTDmmz2JxbwtUvLCTGEcJr14y00W2NMQFx1DYOEZkORKnqSlVdCUSLyE3+D63tKa9y8dDc1fTpGMPU0d0OWb9hTwmhwUG8eq09PWWMCZz6NI5f5+1XAYC3l/d1fouoDXv2m83kFJTz4Pn9Djtc+tn9OpJ511ibE9wYE1D1SRzB4jNuhXcMqjD/hdQ27S6q4JnMTYzv15FRPZJqyt1u5faZS3l/mae7iiPUBis0xgRWfRLHx8BbInKGiJwBvAl85N+w2p7HP1mHy63cd26fg8r/+tk63lu2g9xim7HXGNM81OeRnHvwjPl0g3d5OZ4nq0wjWZlTyLs/ZTNtTA+6JkXVlP/3p2ye/nITU0akcc0p3QMYoTHGHFCfGQDdwAJgK57+E6fj6dBnGoGq8tAHq0mMDGP66b1qylfvKOK+/65gVI9EHrqgv41ya4xpNuq84hCR3sAU789e4C0AVR3XNKG1DZ+u3s3CLfk8fGF/Yn3m2fh6Qy7xkaH8Y8rQes0rbowxTeVIt6rWAt8AE1V1I4CI3NEkUbURLrfyxCfr6JEcxeQT0w5ad8NpPZl8YhrxkfYcgjGmeTnSn7KTgJ3AlyLyrLdh3O6XNKLZS3PYsKeEO8/KIMR7VfHmwu38nFUAYEnDGNMs1Zk4VPU9VZ0M9MEz0ODtQHsReUZEzmqi+FqtSqeLJz9bz4DOcZzT3/OswU/b9/H791bywndbAhydMcbUrT6N46Wq+oZ37vFUYCmeJ63McXhzwXZyCsq56+wMRISSSid3vLWMjrEO/nxh/0CHZ4wxdWpQq6uq7lPVGap6hr8CagtKK53888uNjOqRyJj0dgA8NHcVWfllPHn54IMayY0xprmxx3UC4MXvtrC3pIq7x/dBRPh2w17eXpzNjWN7MqL74Wf6M8aY5sLG5G5ixRXVzPh6M784oT1DuyQAMKpHIn+5aACXDk8NcHTGGHN0dsXRxF75YRtFFU5uO6M3qkpxRTUhwUH8cmQX669hjGkR7JuqCZVUOnn2m82c3qc9A1LjmPPzDsY9kcnm3JKj72yMMc2EXxOHiIwXkXUislFE7q1jm8tEZLWIrBKRN7xlg0XkB2/ZchG53Gf7l0Rki4gs8/4M9uc5NKZXf9hGQVk1t56RTl5JJX+au5rUhMiDxqcyxpjmzm9tHN7h158GzgSygUUiMkdVV/tskw7cB4xW1X0isn+C7TLgKlXdICIpwBIR+cRnXpC7VHWWv2L3h7Iqz9XGab2TGZwWzy1vLqW4opr/u2QgwUHWr9IY03L484pjBLBRVTerahUwE7ig1jbXAU97J4dCVfd4f69X1Q3e1zuAPUCyH2P1u9d/3E5+aRW3npHOZ6t3M/fnHdw8Lp3eHWICHZoxxjSIPxNHZyDLZznbW+arN9BbRL4TkR9FZHztg4jICDwTR23yKX7EewvrSRFp9hNvV1S7+M/XmzmlVzuGdU1g/trd9OkYw41jewY6NGOMabBAP44bAqQDY/H0Sv9aRAbsvyUlIp2AV4GrvcO7g+fW1i48yWQGnl7sD9U+sIhMwzOPCMnJyWRmZvrzPI7oi+3V7C2p4pREITMzk7MSlFNi4Ptvv27yWEpKSgJaF82N1cfBrD4OsLqomz8TRw7gO+RrqrfMVzawQFWrgS0ish5PIlkkIrHAh8D9qvrj/h1Udaf3ZaWIvAjcebg3V9UZeBILGRkZOnbs2OM/o2PgdLn5/ROZDO0Sz9ljBhEcFESXpMiAxAKQmZlJoOqiObL6OJjVxwFWF3Xz562qRUC6iHQXkTBgMjCn1jbv4bnaQETa4bl1tdm7/WzgldqN4N6rELzzoF8IrPTfKRy/D1fsJHtfOTec1pP7Zq/g0v98T5XTffQdjTGmmfJb4lBVJ3Az8AmeGQPfVtVVIvKQiJzv3ewTIE9EVuMZgfcuVc0DLgNOBaYe5rHb10VkBbACaAc87K9zOF6qyjOZm0hvH01ppZMfN+dz6xnphIVY9xljTMvl1zYOVZ0HzKtV9oDPawV+6/3x3eY14LU6jnl640fqH5nrclm7q5hHLuzPXz5ay8DUOCaf2CXQYRljzHEJdON4q/bMV5tIiXOwPb+M3OJKnr1quPXZMMa0eHbPxE+WbNvHwi35XDumBy63cumwVAanxQc6LGOMOW52xeEn//lqE/GRoUwekUZkWAieu3LGGNPy2RWHH2zZW8pna3ZzVt8OrN5RBIDnITBjjGn5LHH4wQvfbiFEhFU7irj5jaX2+K0xplWxxNHI9pVW8c6SLIZ2TWDVjiLuOjvDHr81xrQq9o3WyF5fsI2Kajdb80rplxLLRUNqD89ljDEtmyWORlTpdPHyD9vomRzF7qJK7j2nD0H2+K0xppWxp6oa0fvLdpBbXMmEAZ3o0zGWMekteiR4Y4w5LEscjURVef6bLfTpGMMfz+trT1EZY1otu1XVSL7duJd1u4sZ0iUe67JhjGnNLHE0kue/3YIjJIh3FmeTU1Ae6HCMMcZv7FZVI9i4p5jMdbkECfxqZFfSEgM334YxxvibXXE0ghe+20qQQGhwELec3ivQ4RhjjF9Z4jhO+0qrmLUkC7fC1NHdaB/rCHRIxhjjV5Y4jtMbC7dT5VR6d4jmhlN7BjocY4zxO2vjOA5VTjcvf7+VMentePWakYEOxxhjmoRdcRyHD1fsYE9xJb8aabP6GWPaDkscx0hVeerzDQDsKKgIcDTGGNN0/Jo4RGS8iKwTkY0icm8d21wmIqtFZJWIvOFTfrWIbPD+XO1TPkxEVniP+XcJUBftHzfnsTWvjFhHCL+0Kw5jTBvitzYOEQkGngbOBLKBRSIyR1VX+2yTDtwHjFbVfSLS3lueCPwRGA4osMS77z7gGeA6YAEwDxgPfOSv86jLYx+vA+COM3vjCA1u6rc3xpiA8ecVxwhgo6puVtUqYCZwQa1trgOe9iYEVHWPt/xs4DNVzfeu+wwYLyKdgFhV/VE9c7G+Alzox3M4rM25JSzLKiDWEcKvRnZt6rc3xpiA8udTVZ2BLJ/lbKD2o0e9AUTkOyAYeFBVP65j387en+zDlB9CRKYB0wCSk5PJzMw81vM4xAsrKhBgYjfh+2+/brTjNoWSkpJGrYuWzurjYFYfB1hd1C3Qj+OGAOnAWCAV+FpEBjTGgVV1BjADICMjQ8eOHdsYh6WgrIpFX8xn0tDOPHLpoBY3Cm5mZiaNVRetgdXHwaw+DrC6qJs/b1XlAGk+y6neMl/ZwBxVrVbVLcB6PImkrn1zvK+PdEy/euLTdZRXu7h2TI8WlzSMMaYx+DNxLALSRaS7iIQBk4E5tbZ5D8/VBiLSDs+tq83AJ8BZIpIgIgnAWcAnqroTKBKRUd6nqa4C3vfjORykuKKaNxZsJyY8hBM6xTbV2xpjTLPit1tVquoUkZvxJIFg4AVVXSUiDwGLVXUOBxLEasAF3KWqeQAi8mc8yQfgIVXN976+CXgJiMDzNFWTPVH1h/dW4laYdmqPpnpLY4xpdvzaxqGq8/A8Mutb9oDPawV+6/2pve8LwAuHKV8M9G/0YI+ipKKauct3EhkWzPRxNiaVMabtsp7j9fSH91fhcivXjelBUJBVmzGm7bJvwHr6fuNeHKFB3GzzbRhj2jhLHPXw0/Z97C6u5H/OyiA02KrMGNO22bfgUewsLOfxj9d5xqQaYWNSGWOMJY6j+P3slfywOY9LhqUSFR7o/pLGGBN4ljiOYFlWAV+s3UNwEEwfZ20bxhgDljjqpKr84b0VAPxyRFeSosMDHJExxjQPljjq8NHKXazIKSI4SLjFnqQyxpgaljjqsGVvKQJMGZFG+1hHoMMxxphmwxJHHXYXVRAcBDeOtasNY4zxZY8J1ZKVX8a3G3J5c+F2LhmWRuf4iECHZIwxzYoljlr+NHcVmetycaty41gbk8oYY2qzxOHj01W7+HzNHoIEJo/oQtekqECHZIwxzY61cXiVVjp5cM4qYh0hhAQJt56eHuiQjDGmWbIrDq+nvtjAjsIKAK4/rQcd4+xJKmOMORy74vAakhZP16RIYhwh3HiatW0YY0xdLHF4tY8NZ1teGTec1pP4yLBAh2OMMc1Wm79V9ae5q0iJc/Dp6t20iw7n16O7BTokY4xp1tr0FceXa/fw4ndb+WFzPou27uPOs3oTGdbmc6kxxhyRXxOHiIwXkXUislFE7j3M+qkikisiy7w/13rLx/mULRORChG50LvuJRHZ4rNu8LHEtrekkrvfXU56+2hW5hQwMDWOy4anHc/pGmNMm+C3P69FJBh4GjgTyAYWicgcVV1da9O3VPVm3wJV/RIY7D1OIrAR+NRnk7tUddaxxlbtcjP99Z8oKq/mtN7tmLUkh/9cOZygIDnWQxpjTJvhzyuOEcBGVd2sqlXATOCCYzjOJcBHqlrWWIEt3JLPoq353HFmb95ftoNLhqUypEtCYx3eGGNaNX/e0O8MZPksZwMjD7PdxSJyKrAeuENVs2qtnwz8rVbZIyLyAPAFcK+qVtY+qIhMA6YBJCcnk5mZedD6h0928OaiDYSIMiY2/5D1rVVJSUmbOdf6sPo4mNXHAVYXR6CqfvnBc6XwnM/ylcA/a22TBIR7X18PzK+1vhOQC4TWKhMgHHgZeOBosfTu3VtVVVdkF+hX6/aoquqcZTna9Z4P9NmvN2lb8uWXXwY6hGbF6uNgVh8HWF2oAov1MN+p/rxVlQP4tjanestqqGqeHrhaeA4YVusYlwGzVbXaZ5+d3nOqBF7Ec0vsqLbsLWXqi4u4778ryNlXzgPvr2RQWjxTT+7WsLMyxpg2zp+JYxGQLiLdRSQMzy2nOb4biEgnn8XzgTW1jjEFePNw+4iIABcCK48WiEvhiucW4FblpV+fyEMfrKK0ysVfLx1ISHCbfiLZGGMazG9tHKrqFJGbgU+AYOAFVV0lIg/hufyZA9wqIucDTiAfmLp/fxHphueK5atah35dRJLx3K5aBtxwtFh2lbpxlFfz5nWjWL2ziE9W7ebec/rQq33McZ+nMca0NX7t7aaq84B5tcoe8Hl9H3BfHftuxdPAXrv89IbG4XTDc1cPp0NcOFe+sIAhXeK5bkyPhh7GGGMMbWTIkZToIE7slsivX1pEWZWLxy8ZRLD12TDGmGPSJm7whwbBP+Zv4Ov1uTx4Xj96tY8OdEjGGNNitYnEUe5UnvpiA5OGdmbKCBtWxBhjjkebSBy55UpGhxgeuXAAnoexjDHGHKs2kThU4V+/GkpEWHCgQzHGmBavTSSOdhFCj2Rr1zDGmMbQJhJHVKjdnjLGmMbSJhKHMcaYxmOJwxhjTINY4jDGGNMgljiMMcY0iCUOY4wxDWKJwxhjTINY4jDGGNMgljiMMcY0iHimlW3dRKQYWBfoOJqJdsDeQAfRjFh9HMzq4wCrC+iqqsm1C9vEfBzAOlUdHuggmgMRWWx1cYDVx8GsPg6wuqib3aoyxhjTIJY4jDHGNEhbSRwzAh1AM2J1cTCrj4NZfRxgdVGHNtE4bowxpvG0lSsOY4wxjaRVJw4RGS8i60Rko4jcG+h4mpqIpInIlyKyWkRWicht3vJEEflMRDZ4fycEOtamIiLBIrJURD7wLncXkQXez8hbIhIW6BibiojEi8gsEVkrImtE5KQ2/tm4w/v/ZKWIvCkijrb8+TiSVps4RCQYeBo4B+gLTBGRvoGNqsk5gf9R1b7AKGC6tw7uBb5Q1XTgC+9yW3EbsMZn+THgSVXtBewDrglIVIHxFPCxqvYBBuGplzb52RCRzsCtwHBV7Q8EA5Np25+POrXaxAGMADaq6mZVrQJmAhcEOKYmpao7VfUn7+tiPF8MnfHUw8vezV4GLgxIgE1MRFKBCcBz3mUBTgdmeTdpS3URB5wKPA+gqlWqWkAb/Wx4hQARIhICRAI7aaOfj6NpzYmjM5Dls5ztLWuTRKQbMARYAHRQ1Z3eVbuADoGKq4n9P+BuwO1dTgIKVNXpXW5Ln5HuQC7wovfW3XMiEkUb/Wyoag7wBLAdT8IoBJbQdj8fR9SaE4fxEpFo4F3gdlUt8l2nnsfqWv2jdSIyEdijqksCHUszEQIMBZ5R1SFAKbVuS7WVzwaAty3nAjwJNQWIAsYHNKhmrDUnjhwgzWc51VvWpohIKJ6k8bqq/tdbvFtEOnnXdwL2BCq+JjQaOF9EtuK5bXk6nnv88d5bE9C2PiPZQLaqLvAuz8KTSNriZwPgF8AWVc1V1Wrgv3g+M23183FErTlxLALSvU9FhOFp6JoT4JialPce/vPAGlX9m8+qOcDV3tdXA+83dWxNTVXvU9VUVe2G57MwX1V/BXwJXOLdrE3UBYCq7gKyRCTDW3QGsJo2+Nnw2g6MEpFI7/+b/fXRJj8fR9OqOwCKyLl47msHAy+o6iOBjahpicgpwDfACg7c1/8dnnaOt4EuwDbgMlXND0iQASAiY4E7VXWiiPTAcwWSCCwFrlDVygCG12REZDCeBwXCgM3Ar/H8MdkmPxsi8ifgcjxPIy4FrsXTptEmPx9H0qoThzHGmMbXmm9VGWOM8QNLHMYYYxrEEocxxpgGscRhjDGmQSxxGGOMaRBLHMYcIxFxicgyn59GGxBQRLqJyMrGOp4xjSnk6JsYY+pQrqqDAx2EMU3NrjiMaWQislVE/k9EVojIQhHp5S3vJiLzRWS5iHwhIl285R1EZLaI/Oz9Odl7qGARedY7R8SnIhLh3f5W7xwry0VkZoBO07RhljiMOXYRtW5VXe6zrlBVBwD/xDN6AcA/gJdVdSDwOvB3b/nfga9UdRCe8aJWecvTgadVtR9QAFzsLb8XGOI9zg3+OTVj6mY9x405RiJSoqrRhynfCpyuqpu9g0zuUtUkEdkLdFLVam/5TlVtJyK5QKrvUBbeYfA/806ohIjcA4Sq6sMi8jFQArwHvKeqJX4+VWMOYlccxviH1vG6IXzHRHJxoE1yAp7ZLYcCi3xGbzWmSVjiMMY/Lvf5/YP39fd4RuYF+BWeASjBM0XrjVAzJ3pcXQcVkSAgTVW/BO4B4oBDrnqM8Sf7S8WYYxchIst8lj9W1f2P5CaIyHI8Vw1TvGW34Jlx7y48s+/92lt+GzBDRK7Bc2VxI55Z6A4nGHjNm1wE+Lt3yldjmoy1cRjTyLxtHMNVdW+gYzHGH+xWlTHGmAaxKw5jjDENYlccxhhjGsQShzHGmAaxxGGMMaZBLHEYY4xpEEscxhhjGsQShzHGmAb5/949XKUwHvKcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_docs.plots\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=10)\n",
    "plotter.plot(doc_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcedf2",
   "metadata": {},
   "source": [
    "## d) How does dropouts work, and what is the purpose of dropouts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3765f",
   "metadata": {},
   "source": [
    "dropouts work by dropping a certain percentage of neurons in a layer in every pass. This allows us to create different networks on each pass. essentially we are training different neural networks at each propagation.\n",
    "Since the different networks will overfit in different ways, the net effect of the overfitting is decreased while using dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ff36b",
   "metadata": {},
   "source": [
    "## e) Besides early stopping and dropout, what is another approach that you could take to address overfitting in the model, and how does it work? Implement the approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e5c05",
   "metadata": {},
   "source": [
    "We can introduce a penalty to prevent the weights from getting too big and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7d949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the regularised model\n",
    "def build_regularised_model(input_shape, no_neurons_hidden,first_layer_units,dropout_prob):\n",
    "    model = Sequential([\n",
    "                InputLayer(input_shape),\n",
    "                Dense(first_layer_units,activation='relu',kernel_regularizer=l2(0.001)),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(no_neurons_hidden,activation='relu', kernel_regularizer=l2(0.001)),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(no_neurons_hidden,activation='relu', kernel_regularizer=l2(0.001)),\n",
    "                Dropout(dropout_prob),\n",
    "                Dense(2,activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25b91bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69954, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 2: val_loss improved from 0.69954 to 0.68923, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.68923\n",
      "\n",
      "Epoch 4: val_loss improved from 0.68923 to 0.68795, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 5: val_loss improved from 0.68795 to 0.68761, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.68761\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.68761\n",
      "\n",
      "Epoch 8: val_loss improved from 0.68761 to 0.68758, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 9: val_loss improved from 0.68758 to 0.68746, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 10: val_loss improved from 0.68746 to 0.68674, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.68674\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.68674\n",
      "\n",
      "Epoch 13: val_loss improved from 0.68674 to 0.68660, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 14: val_loss improved from 0.68660 to 0.68628, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.68628\n",
      "\n",
      "Epoch 16: val_loss improved from 0.68628 to 0.68625, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 17: val_loss improved from 0.68625 to 0.68589, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.68589\n",
      "\n",
      "Epoch 25: val_loss improved from 0.68589 to 0.68484, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.68484\n",
      "\n",
      "Epoch 27: val_loss improved from 0.68484 to 0.68472, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 28: val_loss improved from 0.68472 to 0.68445, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.68445\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.68445\n",
      "\n",
      "Epoch 31: val_loss improved from 0.68445 to 0.68443, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.68443\n",
      "\n",
      "Epoch 38: val_loss improved from 0.68443 to 0.68408, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 39: val_loss improved from 0.68408 to 0.68408, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.68408\n",
      "\n",
      "Epoch 48: val_loss improved from 0.68408 to 0.68341, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.68341\n",
      "\n",
      "Epoch 94: val_loss improved from 0.68341 to 0.68312, saving model to ./data/models/PartA_Q3e/best_epoch_weights\n",
      "INFO:tensorflow:Assets written to: ./data/models/PartA_Q3e/best_epoch_weights/assets\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.68312\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.68312\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.68312\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.68312\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.68312\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.68312\n"
     ]
    }
   ],
   "source": [
    "model_path = './data/models/PartA_Q3e/best_epoch_weights'\n",
    "\n",
    "regularised_model = build_regularised_model((X_train_scaled.shape[1],),\n",
    "                            128,\n",
    "                            256,\n",
    "                            0.2)\n",
    "history,timecallbackinstance = compile_and_train(regularised_model,\n",
    "                            no_epochs= 100,\n",
    "                            lr= 0.001,\n",
    "                            batch_size=128,\n",
    "                            x_train= X_train_scaled,\n",
    "                            y_train = y_train,\n",
    "                            x_test = X_test_scaled,\n",
    "                            y_test = y_test,\n",
    "                            model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a43813de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regularised_histories = {}\n",
    "regularised_histories[\"regularised_model\"] = history\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=10)\n",
    "plotter.plot(regularised_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6194584",
   "metadata": {},
   "source": [
    "### How does this work:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d00580",
   "metadata": {},
   "source": [
    "L2 regularisation introduces a weight penalty to ensure that weights do not get overly large during training, thus preventing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac275df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralNetworks",
   "language": "python",
   "name": "neuralnetworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
